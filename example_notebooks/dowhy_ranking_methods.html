<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Ranking of estimation methods for a given dataset &mdash; DoWhy | An end-to-end library for causal inference  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> DoWhy | An end-to-end library for causal inference
          </a>
              <div class="version">
                0.7.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Introducing DoWhy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../readme.html">DoWhy | An end-to-end library for causal inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../readme.html#graphical-models-and-potential-outcomes-best-of-both-worlds">Graphical Models and Potential Outcomes: Best of both worlds</a></li>
<li class="toctree-l1"><a class="reference internal" href="../readme.html#four-steps-of-causal-inference">Four steps of causal inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../readme.html#citing-this-package">Citing this package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../readme.html#roadmap">Roadmap</a></li>
<li class="toctree-l1"><a class="reference internal" href="../readme.html#contributing">Contributing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Quick-Start Tutorial</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="tutorial-causalinference-machinelearning-using-dowhy-econml.html">Tutorial on Causal Inference and its Connections to Machine Learning (Using DoWhy+EconML)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Starter Notebooks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dowhy_simple_example.html">Getting started with DoWhy: A simple example</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_confounder_example.html">Confounding Example: Finding causal effects from observed data</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_estimation_methods.html">DoWhy: Different estimation methods for causal inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy-simple-iv-example.html">Simple example on using Instrumental Variables method for estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="load_graph_example.html">Different ways to load an input graph</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_interpreter.html">DoWhy: Interpreters for Causal Estimators</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_causal_api.html">Demo for the DoWhy causal API</a></li>
<li class="toctree-l1"><a class="reference internal" href="do_sampler_demo.html">Do-sampler Introduction</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Case Study Notebooks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="DoWhy-The%20Causal%20Story%20Behind%20Hotel%20Booking%20Cancellations.html">DoWhy-The Causal Story Behind Hotel Booking Cancellations</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_example_effect_of_memberrewards_program.html">Estimating the effect of a Member Rewards program</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_ihdp_data_example.html">DoWhy example on ihdp (Infant Health and Development Program) dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_twins_example.html">DoWhy example on Twins dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_lalonde_example.html">DoWhy example on the Lalonde dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_refutation_testing.html">Applying refutation tests to the Lalonde and IHDP datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="lalonde_pandas_api.html">Lalonde Pandas API Example</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Notebooks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dowhy-conditional-treatment-effects.html">Conditional Average Treatment Effects (CATE) with DoWhy and EconML</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_mediation_analysis.html">Mediation analysis with DoWhy: Direct and Indirect Effects</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_demo_dummy_outcome_refuter.html">A Simple Example on Creating a Custom Refutation Using User-Defined Outcome Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_multiple_treatments.html">Estimating effect of multiple treatments</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_refuter_notebook.html">Iterating over multiple refutation tests</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_causal_discovery_example.html">Causal Discovery example</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_causal_discovery_example.html#Experiments-on-the-Auto-MPG-dataset">Experiments on the Auto-MPG dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_causal_discovery_example.html#Causal-Discovery-with-Causal-Discovery-Tool-(CDT)">Causal Discovery with Causal Discovery Tool (CDT)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_causal_discovery_example.html#Experiments-on-the-Sachs-dataset">Experiments on the Sachs dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_causal_discovery_example.html#id2">Causal Discovery with Causal Discovery Tool (CDT)</a></li>
<li class="toctree-l1"><a class="reference internal" href="identifying_effects_using_id_algorithm.html">Identifying Effect using ID Algorithm</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Package</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../code_repo.html">Code repository &amp; Versions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dowhy.html">dowhy package</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">DoWhy | An end-to-end library for causal inference</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Ranking of estimation methods for a given dataset</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/example_notebooks/dowhy_ranking_methods.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="Ranking-of-estimation-methods-for-a-given-dataset">
<h1>Ranking of estimation methods for a given dataset<a class="headerlink" href="#Ranking-of-estimation-methods-for-a-given-dataset" title="Permalink to this headline"></a></h1>
<p>We illustrate the comparison of various estimation methods for a given datasets by ranking them according to their performance against refutation tests accounting for both the observed unmodelled confounding error and unobserved confounding error.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Importing all the required libraries</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">xgboost</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pdb</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LassoCV</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">GradientBoostingRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegressionCV</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="kn">from</span> <span class="nn">dowhy</span> <span class="kn">import</span> <span class="n">CausalModel</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>

<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>

<span class="kn">import</span> <span class="nn">dowhy</span>
<span class="kn">from</span> <span class="nn">dowhy.utils</span> <span class="kn">import</span> <span class="n">dgp</span>
<span class="kn">from</span> <span class="nn">dowhy.utils.dgps.linear_dgp</span> <span class="kn">import</span> <span class="n">LinearDataGeneratingProcess</span>
<span class="kn">from</span> <span class="nn">dowhy</span> <span class="kn">import</span> <span class="n">CausalModel</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>
<span class="kn">from</span> <span class="nn">dowhy.causal_refuters.add_unobserved_common_cause</span> <span class="kn">import</span> <span class="n">AddUnobservedCommonCause</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib.lines</span> <span class="k">as</span> <span class="nn">mlines</span>
<span class="kn">import</span> <span class="nn">matplotlib.transforms</span> <span class="k">as</span> <span class="nn">mtransforms</span>

<span class="c1"># Config dict to set the logging level</span>
<span class="kn">import</span> <span class="nn">logging.config</span>
<span class="n">DEFAULT_LOGGING</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;version&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s1">&#39;disable_existing_loggers&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="s1">&#39;loggers&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;level&#39;</span><span class="p">:</span> <span class="s1">&#39;WARN&#39;</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="n">logging</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dictConfig</span><span class="p">(</span><span class="n">DEFAULT_LOGGING</span><span class="p">)</span>
<span class="c1"># Disabling warnings output</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">sklearn.exceptions</span> <span class="kn">import</span> <span class="n">DataConversionWarning</span><span class="p">,</span> <span class="n">ConvergenceWarning</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="n">action</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="n">DataConversionWarning</span><span class="p">)</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="n">action</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="n">ConvergenceWarning</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">convert_singleton_to_float</span><span class="p">(</span><span class="n">arr</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Helper function.&#39;&#39;&#39;</span>
    <span class="n">array</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">type</span><span class="p">(</span><span class="n">arr</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">arr</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">arr</span><span class="p">:</span>
        <span class="k">while</span> <span class="nb">type</span><span class="p">(</span><span class="n">element</span><span class="p">)</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">element</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">element</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;This script only accepts one value for the refute&quot;</span><span class="p">)</span>
            <span class="n">element</span> <span class="o">=</span> <span class="n">element</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">array</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">element</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">array</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">ensure_dir</span><span class="p">(</span><span class="n">file_path</span><span class="p">):</span>
    <span class="n">directory</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">directory</span><span class="p">):</span>
        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">directory</span><span class="p">)</span>

<span class="n">RESULTSFOLDER</span> <span class="o">=</span> <span class="s2">&quot;results/&quot;</span>
<span class="n">ensure_dir</span><span class="p">(</span><span class="n">RESULTSFOLDER</span><span class="p">)</span>
<span class="c1"># Create the estimator named tuple to wrap the name and properties</span>
<span class="n">Estimator</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;Estimator&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">,</span><span class="s1">&#39;params&#39;</span><span class="p">])</span>
<span class="n">Refuter</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;Refuter&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">,</span><span class="s1">&#39;params&#39;</span><span class="p">])</span>

<span class="k">class</span> <span class="nc">Experiment</span><span class="p">():</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Class to define the experiment setup to compare a list of estimators across a list of refuters for the given dataset.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;experiment_name&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">experiment_id</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;experiment_id&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_experiments</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;num_experiments&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_sizes</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;sample_sizes&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dgps</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;dgps&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimators</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;estimators&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">refuters</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;refuters&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">simulate_unobserved_confounding</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;simulate_unobserved_confounding&quot;</span><span class="p">]</span>

        <span class="c1"># Handle input errors in sample_sizes</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_sizes</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="o">==</span> <span class="kc">False</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_sizes</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">int</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The input to &quot;sample_sizes&quot; should be an int or a list&#39;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">sample_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_sizes</span><span class="p">]</span>

        <span class="c1"># Handle input errors in DGPs</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dgps</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="o">==</span> <span class="kc">False</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dgps</span><span class="p">,</span> <span class="n">DataGeneratingProcess</span><span class="p">)</span> <span class="o">==</span> <span class="kc">False</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The input to &quot;dgps&quot; should be a list or a subclass of &quot;DataGeneratingProcess&quot;&#39;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">dgps</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">dgps</span><span class="p">]</span>

        <span class="c1"># Handle inputs errors in estimators</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="o">==</span> <span class="kc">False</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">,</span> <span class="n">Estimator</span><span class="p">)</span> <span class="o">==</span> <span class="kc">False</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The input to &quot;estimators&quot; should be a list or an Estimator namedtuple&#39;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">estimators</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">]</span>

        <span class="c1"># Handle input errors in refuters</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">refuters</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="o">==</span> <span class="kc">False</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">refuters</span><span class="p">,</span> <span class="n">Refuter</span><span class="p">)</span> <span class="o">==</span> <span class="kc">False</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The input to &quot;refuters&quot; should be a list of a Refuter namedtuple&#39;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">refuters</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">refuters</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">experiment</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">Running Experiment:&quot;</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">experiment_name</span> <span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">experiment_id</span><span class="p">)</span> <span class="p">)</span>

        <span class="k">for</span> <span class="n">exp</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_experiments</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">Running Experiment Number:&quot;</span><span class="p">,</span><span class="n">exp</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">sample_size</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_sizes</span><span class="p">:</span>

                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">Current Sample Size:&quot;</span><span class="p">,</span><span class="n">sample_size</span><span class="p">)</span>

                <span class="k">for</span> <span class="n">dgp</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">dgps</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">The current DGP:&quot;</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="n">dgp</span><span class="p">)</span>
                    <span class="n">estimates</span> <span class="o">=</span> <span class="p">[]</span>
                    <span class="n">estimate_values</span> <span class="o">=</span> <span class="p">[]</span>
                    <span class="n">estimated_effect</span> <span class="o">=</span> <span class="p">[]</span>
                    <span class="n">new_effect</span> <span class="o">=</span> <span class="p">[]</span>
                    <span class="n">p_value</span> <span class="o">=</span> <span class="p">[]</span>
                    <span class="n">data</span> <span class="o">=</span> <span class="n">dgp</span><span class="o">.</span><span class="n">generate_data</span><span class="p">(</span><span class="n">sample_size</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;printing data shape&quot;</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="n">dgp</span><span class="o">.</span><span class="n">true_value</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;check&quot;</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">dgp</span><span class="o">.</span><span class="n">treatment_is_binary</span><span class="p">:</span>
                        <span class="n">data</span><span class="p">[</span><span class="n">dgp</span><span class="o">.</span><span class="n">treatment</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">dgp</span><span class="o">.</span><span class="n">treatment</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">bool</span><span class="p">)</span>
                    <span class="c1">#k = len(dgp.confounder)-4</span>
                    <span class="c1">#confounder_list = random.sample(dgp.confounder, k)</span>
                    <span class="n">confounder_list</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;w2&#39;</span><span class="p">,</span><span class="s1">&#39;w3&#39;</span><span class="p">]</span>


                    <span class="n">s</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">confounder_list</span><span class="p">)</span>
                    <span class="n">unobserved_confounders</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">dgp</span><span class="o">.</span><span class="n">confounder</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">s</span><span class="p">]</span>
                    <span class="n">df_unobserved_confounders</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[[</span><span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">unobserved_confounders</span><span class="p">]])</span>

                    <span class="n">df_unobserved_confounders</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;results/unobserved_confounders.csv&quot;</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;printing length of confounder list:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">confounder_list</span><span class="p">))</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;printing confounder list:&quot;</span><span class="p">,</span> <span class="n">confounder_list</span><span class="p">)</span>



                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;data columns&quot;</span><span class="p">)</span>

                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;data columns&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
                    <span class="n">model</span> <span class="o">=</span> <span class="n">CausalModel</span><span class="p">(</span>
                        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">,</span>
                        <span class="n">treatment</span> <span class="o">=</span> <span class="n">dgp</span><span class="o">.</span><span class="n">treatment</span><span class="p">,</span>
                        <span class="n">outcome</span> <span class="o">=</span> <span class="n">dgp</span><span class="o">.</span><span class="n">outcome</span><span class="p">,</span>
                        <span class="n">common_causes</span> <span class="o">=</span> <span class="n">confounder_list</span><span class="p">,</span>
                        <span class="n">effect_modifiers</span> <span class="o">=</span> <span class="n">dgp</span><span class="o">.</span><span class="n">effect_modifier</span>
                    <span class="p">)</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">view_model</span><span class="p">()</span>
                    <span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span><span class="p">,</span> <span class="n">display</span>
                    <span class="n">display</span><span class="p">(</span><span class="n">Image</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s2">&quot;causal_model.png&quot;</span><span class="p">))</span>

                    <span class="n">identified_estimand</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">identify_effect</span><span class="p">(</span><span class="n">proceed_when_unidentifiable</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;identified_estimand:&quot;</span><span class="p">,</span> <span class="n">identified_estimand</span><span class="p">)</span>
                    <span class="c1">#print(&quot;identified_estimand:&quot;, identified_estimand)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">Running the estimators:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">estimator</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The current estimator:&quot;</span><span class="p">,</span> <span class="n">estimator</span><span class="p">)</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;estimator.params&quot;</span><span class="p">,</span> <span class="n">estimator</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
                        <span class="n">estimate</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">estimate_effect</span><span class="p">(</span>
                            <span class="n">identified_estimand</span><span class="p">,</span>
                            <span class="n">method_name</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                            <span class="n">method_params</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">params</span>
                        <span class="p">)</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;printing estimate&#39;s type&quot;</span><span class="p">)</span>
                        <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">estimate</span><span class="p">))</span>
                        <span class="n">estimates</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">estimate</span><span class="p">)</span>
                        <span class="n">estimate_values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">estimate</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
                    <span class="n">estimate_values</span> <span class="o">=</span> <span class="n">convert_singleton_to_float</span><span class="p">(</span><span class="n">estimate_values</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;estimate_values&quot;</span><span class="p">,</span> <span class="n">estimate_values</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">Running the refuters:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">refuter</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">refuters</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The current refuter:&quot;</span><span class="p">,</span> <span class="n">refuter</span><span class="p">)</span>

                        <span class="k">for</span> <span class="n">estimate</span> <span class="ow">in</span> <span class="n">estimates</span><span class="p">:</span>
                            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">simulate_unobserved_confounding</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
                                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;********</span><span class="si">%%%%%%%%</span><span class="s2">%$$$$$&amp;&amp;^**^^^^*^*^*&quot;</span><span class="p">)</span>
                                <span class="k">if</span> <span class="n">refuter</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;dummy_outcome_refuter&#39;</span><span class="p">:</span>
                                    <span class="n">add_unobserved_confounder</span> <span class="o">=</span> <span class="n">AddUnobservedCommonCause</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">identified_estimand</span><span class="p">,</span> <span class="n">estimate</span><span class="p">)</span>
                                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;add_unobserved_confounder&quot;</span><span class="p">,</span> <span class="n">add_unobserved_confounder</span><span class="p">)</span>
                                    <span class="n">unobserved_confounder_values</span> <span class="o">=</span> <span class="n">add_unobserved_confounder</span><span class="o">.</span><span class="n">include_simulated_confounder</span><span class="p">(</span><span class="n">convergence_threshold</span> <span class="o">=</span> <span class="mf">0.11</span><span class="p">,</span> <span class="n">c_star_max</span> <span class="o">=</span> <span class="mi">1500</span><span class="p">)</span>
                                    <span class="n">refuter</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;unobserved_confounder_values&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">unobserved_confounder_values</span>
                                    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;refuter.params&#39;</span><span class="p">,</span> <span class="n">refuter</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
                            <span class="n">refute</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">refute_estimate</span><span class="p">(</span>
                                <span class="n">identified_estimand</span><span class="p">,</span>
                                <span class="n">estimate</span><span class="p">,</span>
                                <span class="n">method_name</span> <span class="o">=</span> <span class="n">refuter</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                                <span class="o">**</span><span class="n">refuter</span><span class="o">.</span><span class="n">params</span><span class="p">,</span>



                            <span class="p">)</span>
                            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;printing refute&#39;s type&quot;</span><span class="p">)</span>
                            <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">refute</span><span class="p">))</span>
                            <span class="k">if</span><span class="p">(</span><span class="n">refuter</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;dummy_outcome_refuter&#39;</span><span class="p">):</span>
                                <span class="n">refute</span> <span class="o">=</span> <span class="n">refute</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                            <span class="k">if</span> <span class="n">refute</span><span class="o">.</span><span class="n">refutation_result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                                <span class="n">p_value</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">refute</span><span class="o">.</span><span class="n">refutation_result</span><span class="p">[</span><span class="s1">&#39;p_value&#39;</span><span class="p">])</span>
                            <span class="k">else</span><span class="p">:</span>
                                <span class="n">p_value</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>

                            <span class="n">estimated_effect</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">refute</span><span class="o">.</span><span class="n">estimated_effect</span><span class="p">)</span>
                            <span class="c1">#print(&quot;refute.estimate_effect()&quot;, refute.estimate_effect())</span>
                            <span class="n">new_effect</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">refute</span><span class="o">.</span><span class="n">new_effect</span><span class="p">)</span>

                    <span class="n">estimated_effect</span> <span class="o">=</span> <span class="n">convert_singleton_to_float</span><span class="p">(</span><span class="n">estimated_effect</span><span class="p">)</span>
                    <span class="n">new_effect</span> <span class="o">=</span> <span class="n">convert_singleton_to_float</span><span class="p">(</span><span class="n">new_effect</span><span class="p">)</span>
                    <span class="n">p_value</span> <span class="o">=</span> <span class="n">convert_singleton_to_float</span><span class="p">(</span><span class="n">p_value</span><span class="p">)</span>
                    <span class="n">true_value</span> <span class="o">=</span> <span class="n">convert_singleton_to_float</span><span class="p">(</span><span class="n">dgp</span><span class="o">.</span><span class="n">true_value</span><span class="p">)</span>

                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;estimated effect&quot;</span><span class="p">,</span> <span class="n">estimated_effect</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;new_effect&quot;</span><span class="p">,</span> <span class="n">new_effect</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;p_value&quot;</span><span class="p">,</span> <span class="n">p_value</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;true value&quot;</span><span class="p">,</span> <span class="n">true_value</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">exp</span><span class="p">,</span> <span class="n">sample_size</span><span class="p">,</span> <span class="n">dgp</span><span class="o">.</span><span class="n">NAME</span><span class="p">,</span> <span class="o">*</span><span class="n">estimate_values</span><span class="p">,</span> <span class="o">*</span><span class="n">estimated_effect</span><span class="p">,</span> <span class="o">*</span><span class="n">new_effect</span><span class="p">,</span> <span class="o">*</span><span class="n">p_value</span><span class="p">,</span> <span class="n">true_value</span><span class="p">])</span>


        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">Completed all experiments. Saving the data...&quot;</span><span class="p">)</span>

        <span class="n">COLUMNS</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;EXPERIMENT&#39;</span><span class="p">,</span> <span class="s1">&#39;SAMPLE_SIZE&#39;</span><span class="p">,</span> <span class="s1">&#39;DGP&#39;</span><span class="p">]</span>
        <span class="n">RESULT_CATEGORIES</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ESTIMATED_EFFECT&#39;</span><span class="p">,</span> <span class="s1">&#39;NEW_EFFECT&#39;</span><span class="p">,</span> <span class="s1">&#39;P_VALUE&#39;</span><span class="p">]</span>
        <span class="n">estimator_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">estimator</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">estimator</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">]</span>
        <span class="n">refuter_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">refuter</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">refuter</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">refuters</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">estimator_name</span> <span class="ow">in</span> <span class="n">estimator_names</span><span class="p">:</span>
            <span class="n">COLUMNS</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;ORIGINAL_ESTIMATE&#39;</span><span class="o">+</span> <span class="s1">&#39;:&#39;</span> <span class="o">+</span> <span class="n">estimator_name</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">result_category</span> <span class="ow">in</span> <span class="n">RESULT_CATEGORIES</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">refuter_name</span> <span class="ow">in</span> <span class="n">refuter_names</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">estimator_name</span> <span class="ow">in</span> <span class="n">estimator_names</span><span class="p">:</span>
                    <span class="n">COLUMNS</span> <span class="o">+=</span> <span class="p">[</span><span class="n">refuter_name</span> <span class="o">+</span> <span class="s1">&#39;:&#39;</span> <span class="o">+</span> <span class="n">estimator_name</span> <span class="o">+</span> <span class="s1">&#39;:&#39;</span> <span class="o">+</span> <span class="n">result_category</span><span class="p">]</span>

        <span class="n">COLUMNS</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;TRUE_VALUE&#39;</span><span class="p">]</span>

        <span class="n">csv_file</span> <span class="o">=</span> <span class="n">RESULTSFOLDER</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">experiment_name</span><span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">experiment_id</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">utcnow</span><span class="p">()</span><span class="o">.</span><span class="n">date</span><span class="p">())</span> <span class="o">+</span> <span class="s1">&#39;_data.csv&#39;</span>
        <span class="n">onlyres_csv_file</span> <span class="o">=</span> <span class="n">RESULTSFOLDER</span> <span class="o">+</span> <span class="s2">&quot;onlyres_&quot;</span><span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">experiment_name</span><span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">experiment_id</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">utcnow</span><span class="p">())</span> <span class="o">+</span> <span class="s1">&#39;_data.csv&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">results</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="n">COLUMNS</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">results</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">csv_file</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">),</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Data has been saved in &quot;</span><span class="p">,</span><span class="n">csv_file</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">csv_file</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Defining the Data Generating Process</span>
<span class="n">ldgp</span> <span class="o">=</span> <span class="n">LinearDataGeneratingProcess</span><span class="p">(</span><span class="n">treatment</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;t1&#39;</span><span class="p">],</span> <span class="n">outcome</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">],</span> <span class="n">confounder</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;w1&#39;</span><span class="p">,</span><span class="s1">&#39;w2&#39;</span><span class="p">,</span> <span class="s1">&#39;w3&#39;</span><span class="p">,</span><span class="s1">&#39;w4&#39;</span><span class="p">,</span><span class="s1">&#39;w5&#39;</span><span class="p">,</span><span class="s1">&#39;w6&#39;</span><span class="p">],</span> <span class="n">effect_modifier</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span><span class="s1">&#39;x2&#39;</span><span class="p">],</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">treatment_is_binary</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1">#Defining the sample size</span>
<span class="n">sample_size</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="n">dgp_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;ldgp&#39;</span><span class="p">:</span><span class="n">ldgp</span><span class="p">}</span>
<span class="n">dgp_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">dgp_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="n">dgp_dict</span><span class="p">[</span><span class="s1">&#39;ldgp&#39;</span><span class="p">]</span> <span class="p">)</span>


<span class="c1"># Create a namedtuple to store the name of the estimator and the parameters passed</span>
<span class="n">estimator_list</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;backdoor.linear_regression&quot;</span><span class="p">,</span>
                  <span class="c1">#&quot;backdoor.propensity_score_stratification&quot;,</span>
                  <span class="s2">&quot;backdoor.propensity_score_matching&quot;</span><span class="p">,</span>
                  <span class="s2">&quot;backdoor.propensity_score_weighting&quot;</span><span class="p">,</span>
                  <span class="s2">&quot;backdoor.econml.dml.DML&quot;</span><span class="p">,</span>
                  <span class="s2">&quot;backdoor.econml.dr.LinearDRLearner&quot;</span><span class="p">,</span>
                  <span class="c1">#&quot;backdoor.econml.metalearners.TLearner&quot;,</span>
                  <span class="c1">#&quot;backdoor.econml.metalearners.XLearner&quot;,</span>
                  <span class="c1">#&quot;backdoor.causalml.inference.meta.LRSRegressor&quot;,</span>
                  <span class="c1">#&quot;backdoor.causalml.inference.meta.XGBTRegressor&quot;,</span>
                  <span class="c1">#&quot;backdoor.causalml.inference.meta.MLPTRegressor&quot;,</span>
                  <span class="c1">#&quot;backdoor.causalml.inference.meta.BaseXRegressor&quot;</span>
                <span class="p">]</span>
<span class="n">method_params</span><span class="o">=</span> <span class="p">[</span>    <span class="kc">None</span><span class="p">,</span>
                    <span class="c1">#None,</span>
                    <span class="p">{</span> <span class="s2">&quot;init_params&quot;</span><span class="p">:{}</span> <span class="p">},</span>
                    <span class="p">{</span> <span class="s2">&quot;init_params&quot;</span><span class="p">:{}</span> <span class="p">},</span>
                    <span class="p">{</span><span class="s2">&quot;init_params&quot;</span><span class="p">:{</span><span class="s1">&#39;model_y&#39;</span><span class="p">:</span><span class="n">GradientBoostingRegressor</span><span class="p">(),</span>
                                    <span class="s1">&#39;model_t&#39;</span><span class="p">:</span> <span class="n">GradientBoostingRegressor</span><span class="p">(),</span>
                                    <span class="s2">&quot;model_final&quot;</span><span class="p">:</span><span class="n">LassoCV</span><span class="p">(</span><span class="n">fit_intercept</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
                                    <span class="s1">&#39;featurizer&#39;</span><span class="p">:</span><span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">include_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)},</span>
                     <span class="s2">&quot;fit_params&quot;</span><span class="p">:{}},</span>
                    <span class="p">{</span><span class="s2">&quot;init_params&quot;</span><span class="p">:{</span> <span class="s1">&#39;model_propensity&#39;</span><span class="p">:</span> <span class="n">LogisticRegressionCV</span><span class="p">(</span><span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">),</span>
                        <span class="p">},</span>
                    <span class="s2">&quot;fit_params&quot;</span><span class="p">:{}</span>
                    <span class="p">},</span>
                    <span class="sd">&#39;&#39;&#39;{&quot;init_params&quot;: {&#39;models&#39;: GradientBoostingRegressor(n_estimators=100, max_depth=6, min_samples_leaf=int(sample_size/100))</span>
<span class="sd">                                    },</span>
<span class="sd">                    &quot;fit_params&quot;:{}</span>
<span class="sd">                    },</span>
<span class="sd">                    {&quot;init_params&quot;:{&#39;models&#39;: GradientBoostingRegressor(n_estimators=100, max_depth=6, min_samples_leaf=int(sample_size/100)),</span>
<span class="sd">                        &#39;propensity_model&#39;: RandomForestClassifier(n_estimators=100, max_depth=6,</span>
<span class="sd">                                                                              min_samples_leaf=int(sample_size/100))</span>
<span class="sd">                        },</span>
<span class="sd">                     &quot;fit_params&quot;:{}</span>
<span class="sd">                    },</span>
<span class="sd">                    {&quot;init_params&quot;:{},},</span>
<span class="sd">                    {&quot;init_params&quot;:{</span>
<span class="sd">                        &#39;learner&#39;:XGBRegressor()</span>
<span class="sd">                        }</span>
<span class="sd">                    }&#39;&#39;&#39;</span>
                <span class="p">]</span>
<span class="n">estimator_tuples</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">refuter_tuples</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">refuter_list</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;dummy_outcome_refuter&#39;</span><span class="p">]</span>
<span class="n">refuter_params</span> <span class="o">=</span> <span class="p">[{</span><span class="s1">&#39;num_simulations&#39;</span><span class="p">:</span><span class="mi">5</span><span class="p">,</span><span class="s1">&#39;transformation_list&#39;</span><span class="p">:</span> <span class="p">[(</span><span class="s1">&#39;random_forest&#39;</span><span class="p">,{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span><span class="mi">100</span><span class="p">,</span> <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span><span class="mi">6</span><span class="p">})],</span> <span class="s1">&#39;true_causal_effect&#39;</span><span class="p">:(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="mf">0.5</span><span class="p">)}]</span>


<span class="c1"># Iterate through the names and parameters to create a list of namedtuples</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">estimator_list</span><span class="p">,</span><span class="n">method_params</span><span class="p">):</span>
    <span class="n">estimator_tuples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Estimator</span><span class="o">.</span><span class="n">_make</span><span class="p">([</span><span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="p">]))</span>

<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">refuter_list</span><span class="p">,</span> <span class="n">refuter_params</span><span class="p">):</span>
    <span class="n">refuter_tuples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Refuter</span><span class="o">.</span><span class="n">_make</span><span class="p">([</span><span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="p">]))</span>
<br/></pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_MAEs</span><span class="p">(</span><span class="n">res</span><span class="p">):</span>
    <span class="n">true_value_column</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">estimate_columns</span><span class="o">=</span><span class="n">res</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">3</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="c1">#print(estimate_columns)</span>
    <span class="c1">#print(type(estimate_columns))</span>
    <span class="n">estimate_columns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Index</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="s2">&quot;TRUE_VALUE&quot;</span><span class="p">]))</span>
    <span class="c1">#print(estimate_columns)</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
    <span class="n">MAE</span> <span class="o">=</span><span class="p">{}</span>
    <span class="k">for</span> <span class="n">colname</span> <span class="ow">in</span> <span class="n">estimate_columns</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">colname</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;ORIGINAL_ESTIMATE:backdoor.propensity_score_weighting&#39;</span><span class="p">,):</span>
                           <span class="c1">#&#39;ORIGINAL_ESTIMATE:backdoor.econml.metalearners.TLearner&#39;):</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="n">colname</span><span class="p">],</span> <span class="n">res</span><span class="p">[</span><span class="s2">&quot;TRUE_VALUE&quot;</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;None&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">colname</span><span class="p">)</span>
            <span class="s2">&quot;Mean Absolute Error (MAE): </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="n">colname</span><span class="p">],</span> <span class="n">res</span><span class="p">[</span><span class="s2">&quot;TRUE_VALUE&quot;</span><span class="p">]))</span>
            <span class="n">MAE</span><span class="p">[</span><span class="n">colname</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="n">colname</span><span class="p">],</span> <span class="n">res</span><span class="p">[</span><span class="s2">&quot;TRUE_VALUE&quot;</span><span class="p">])</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Calibration plot showing the accuracy of different causal estimators [P(T=1)=0.9]&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Estimated effect&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;True causal effect&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper center&#39;</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.20</span><span class="p">),</span>
              <span class="n">fancybox</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">shadow</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ncol</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Printing MAE of various estimates: &quot;</span><span class="p">)</span>
    <span class="n">MAE_values</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">MAE</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">item</span><span class="p">:</span> <span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)}</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">MAE_values</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_estimators_and_refuters</span><span class="p">(</span><span class="n">refuter</span><span class="p">,</span> <span class="n">estimator</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="s1">&#39;EXPERIMENT&#39;</span><span class="p">])</span>
    <span class="n">y1</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="n">refuter</span><span class="o">+</span><span class="s1">&#39;:&#39;</span><span class="o">+</span><span class="n">estimator</span><span class="o">+</span><span class="s1">&#39;:ESTIMATED_EFFECT&#39;</span><span class="p">])</span>
    <span class="n">y2</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="n">refuter</span><span class="o">+</span><span class="s1">&#39;:&#39;</span><span class="o">+</span><span class="n">estimator</span><span class="o">+</span><span class="s1">&#39;:NEW_EFFECT&#39;</span><span class="p">])</span>
    <span class="c1">#print(res[&#39;TRUE_VALUE&#39;])</span>
    <span class="n">y3</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="s1">&#39;TRUE_VALUE&#39;</span><span class="p">])</span>
    <span class="n">y4</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="n">refuter</span><span class="o">+</span><span class="s1">&#39;:&#39;</span><span class="o">+</span><span class="n">estimator</span><span class="o">+</span><span class="s1">&#39;:P_VALUE&#39;</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;Estimated Effect&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y2</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;New Effect&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y3</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span><span class="s2">&quot;green&quot;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;True Value&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y4</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span><span class="s2">&quot;yellow&quot;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;P Value&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;EXPERIMENT&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;EFFECT&quot;</span><span class="p">)</span>
    <span class="n">legend</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;small&#39;</span><span class="p">,</span> <span class="n">fancybox</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">estimator</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">estimator</span><span class="o">+</span><span class="s1">&#39;.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_deviations</span><span class="p">(</span><span class="n">estimator_list</span><span class="p">,</span> <span class="n">deviation_list</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">estimator_list</span><span class="p">,</span> <span class="n">deviation_list</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">estimator_list</span><span class="p">,</span> <span class="n">estimator_list</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="s1">&#39;vertical&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</section>
<section id="Observed-unmodelled-confounding-error">
<h1>Observed unmodelled confounding error<a class="headerlink" href="#Observed-unmodelled-confounding-error" title="Permalink to this headline"></a></h1>
<p>For each estimator, we use dummy outcome refuter to check the observed unmodelled confounding error for each estimator. That is, we run the refutation test for each estimator only on the observed confounders and analyse what amount of confounding error is present unmodelled amongst the observed variables.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the properties of the experiment</span>
<span class="c1"># The name of the experiment</span>
<span class="c1"># The experiment ID</span>
<span class="c1"># The number of experiments to be run with the SAME parameters</span>
<span class="c1"># The size of the samples to be run</span>
<span class="c1"># The list of DGPs to be run</span>
<span class="c1"># The list of estimators</span>
<span class="n">observed_confounding_error</span> <span class="o">=</span> <span class="n">Experiment</span><span class="p">(</span>
    <span class="n">experiment_name</span><span class="o">=</span><span class="s1">&#39;Test&#39;</span><span class="p">,</span>
    <span class="n">experiment_id</span><span class="o">=</span><span class="s1">&#39;1&#39;</span><span class="p">,</span>
    <span class="n">num_experiments</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="c1"># 10</span>
    <span class="n">sample_sizes</span><span class="o">=</span><span class="n">sample_size</span><span class="p">,</span>
    <span class="n">dgps</span><span class="o">=</span><span class="n">dgp_list</span><span class="p">,</span>
    <span class="n">estimators</span><span class="o">=</span><span class="n">estimator_tuples</span><span class="p">,</span>
    <span class="n">refuters</span><span class="o">=</span><span class="n">refuter_tuples</span><span class="p">,</span>
    <span class="n">simulate_unobserved_confounding</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span>

<span class="c1"># Run the experiment</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">observed_confounding_error</span><span class="o">.</span><span class="n">experiment</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>


Running Experiment: Test_1


Running Experiment Number: 0


Current Sample Size: 1000


The current DGP:

        Linear Data Generating Process
        -------------------------------

        treatment:[&#39;t1&#39;]
        outcome:[&#39;y&#39;]
        confounder: [&#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;]
        effect_modifier: [&#39;x1&#39;, &#39;x2&#39;]
        weights: {}
        bias: {}
        seed: None
        treatment_is_binary: True
        percentile: 0.9

printing data shape
(1000, 10)
[-2.16021815]
check
printing length of confounder list: 2
printing confounder list: [&#39;w2&#39;, &#39;w3&#39;]
data columns
data columns Index([&#39;x1&#39;, &#39;x2&#39;, &#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;, &#39;t1&#39;, &#39;y&#39;], dtype=&#39;object&#39;)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_dowhy_ranking_methods_11_1.png" src="../_images/example_notebooks_dowhy_ranking_methods_11_1.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
identified_estimand: Estimand type: nonparametric-ate

### Estimand : 1
Estimand name: backdoor
Estimand expression:
  d
─────(Expectation(y|w3,w2))
d[t₁]
Estimand assumption 1, Unconfoundedness: If U→{t1} and U→y then P(y|t1,w3,w2,U) = P(y|t1,w3,w2)

### Estimand : 2
Estimand name: iv
No such variable(s) found!

### Estimand : 3
Estimand name: frontdoor
No such variable(s) found!



Running the estimators:

The current estimator: Estimator(name=&#39;backdoor.linear_regression&#39;, params=None)
estimator.params None
linear_regression
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: None, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_matching&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_matching
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/amshar/python-environments/vpy38/lib/python3.8/site-packages/statsmodels/regression/linear_model.py:1860: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_weighting&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_weighting
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dml.DML&#39;, params={&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2022-03-20 20:15:50.483900: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libcudart.so.11.0&#39;; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2022-03-20 20:15:50.484103: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dr.LinearDRLearner&#39;, params={&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
estimate_values [65.21585430509731, 70.40508337488912, 65.04045602154363, 51.35200884561789, 66.41319376643672]


Running the refuters:

The current refuter: Refuter(name=&#39;dummy_outcome_refuter&#39;, params={&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;})
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
estimated effect [0.5, 0.5, 0.5, 0.5, 0.5]
new_effect [2.0929152238389706, -1.1110843846427647, -0.2540771054226735, -0.1469346741706295, 0.6465815042857738]
p_value [0.2846465814215726, 0.2696935715373422, 0.4258007581024964, 0.013852572988622747, 0.4770727604926411]
true value -2.1602181502819833


Running Experiment Number: 1


Current Sample Size: 1000


The current DGP:

        Linear Data Generating Process
        -------------------------------

        treatment:[&#39;t1&#39;]
        outcome:[&#39;y&#39;]
        confounder: [&#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;]
        effect_modifier: [&#39;x1&#39;, &#39;x2&#39;]
        weights: {&#39;confounder=&gt;treatment&#39;: array([[100.02566399],
       [  0.50710254],
       [  0.39475248],
       [  1.18939194],
       [ -0.82750088],
       [ -0.6717412 ]]), &#39;confounder=&gt;outcome&#39;: array([[101.12607252],
       [ -0.50810067],
       [  0.36814479],
       [ -1.21534504],
       [ -0.25090022],
       [ -0.44676619]]), &#39;effect_modifier=&gt;outcome&#39;: array([[ 0.34718263],
       [-1.88433481]]), &#39;treatment=&gt;outcome&#39;: array([[-2.16021815]])}
        bias: {&#39;confounder=&gt;treatment&#39;: array([0.77991225]), &#39;confounder=&gt;outcome&#39;: array([-0.34131343])}
        seed: None
        treatment_is_binary: True
        percentile: 0.9

printing data shape
(1000, 10)
[-0.6430417]
check
printing length of confounder list: 2
printing confounder list: [&#39;w2&#39;, &#39;w3&#39;]
data columns
data columns Index([&#39;x1&#39;, &#39;x2&#39;, &#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;, &#39;t1&#39;, &#39;y&#39;], dtype=&#39;object&#39;)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_dowhy_ranking_methods_11_21.png" src="../_images/example_notebooks_dowhy_ranking_methods_11_21.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
identified_estimand: Estimand type: nonparametric-ate

### Estimand : 1
Estimand name: backdoor
Estimand expression:
  d
─────(Expectation(y|w3,w2))
d[t₁]
Estimand assumption 1, Unconfoundedness: If U→{t1} and U→y then P(y|t1,w3,w2,U) = P(y|t1,w3,w2)

### Estimand : 2
Estimand name: iv
No such variable(s) found!

### Estimand : 3
Estimand name: frontdoor
No such variable(s) found!



Running the estimators:

The current estimator: Estimator(name=&#39;backdoor.linear_regression&#39;, params=None)
estimator.params None
linear_regression
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: None, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_matching&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_matching
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_weighting&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_weighting
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dml.DML&#39;, params={&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dr.LinearDRLearner&#39;, params={&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
estimate_values [62.6574487667095, 53.429898041643185, 62.7108331661941, 50.00970625778995, 63.0352521639778]


Running the refuters:

The current refuter: Refuter(name=&#39;dummy_outcome_refuter&#39;, params={&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;})
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
estimated effect [0.5, 0.5, 0.5, 0.5, 0.5]
new_effect [-1.3891004342734692, -0.06921694510514867, 1.0790696052933428, -0.3929119921316152, 2.4877914264565133]
p_value [0.23991797333558673, 0.4216319530833639, 0.27450321522196186, 0.12792078656210903, 0.2835785799824565]
true value -0.6430416974361974


Running Experiment Number: 2


Current Sample Size: 1000


The current DGP:

        Linear Data Generating Process
        -------------------------------

        treatment:[&#39;t1&#39;]
        outcome:[&#39;y&#39;]
        confounder: [&#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;]
        effect_modifier: [&#39;x1&#39;, &#39;x2&#39;]
        weights: {&#39;confounder=&gt;treatment&#39;: array([[ 9.88270080e+01],
       [ 1.78565335e-01],
       [-6.04984285e-01],
       [-3.61862038e-01],
       [-7.25359141e-02],
       [-1.51937973e-01]]), &#39;confounder=&gt;outcome&#39;: array([[ 1.00169212e+02],
       [-1.46817274e+00],
       [-5.86370247e-02],
       [ 4.32271183e-01],
       [-6.19866127e-01],
       [ 1.34407418e-01]]), &#39;effect_modifier=&gt;outcome&#39;: array([[0.33481771],
       [1.72911678]]), &#39;treatment=&gt;outcome&#39;: array([[-0.6430417]])}
        bias: {&#39;confounder=&gt;treatment&#39;: array([0.22945838]), &#39;confounder=&gt;outcome&#39;: array([-1.22111983])}
        seed: None
        treatment_is_binary: True
        percentile: 0.9

printing data shape
(1000, 10)
[-0.73428369]
check
printing length of confounder list: 2
printing confounder list: [&#39;w2&#39;, &#39;w3&#39;]
data columns
data columns Index([&#39;x1&#39;, &#39;x2&#39;, &#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;, &#39;t1&#39;, &#39;y&#39;], dtype=&#39;object&#39;)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_dowhy_ranking_methods_11_39.png" src="../_images/example_notebooks_dowhy_ranking_methods_11_39.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
identified_estimand: Estimand type: nonparametric-ate

### Estimand : 1
Estimand name: backdoor
Estimand expression:
  d
─────(Expectation(y|w3,w2))
d[t₁]
Estimand assumption 1, Unconfoundedness: If U→{t1} and U→y then P(y|t1,w3,w2,U) = P(y|t1,w3,w2)

### Estimand : 2
Estimand name: iv
No such variable(s) found!

### Estimand : 3
Estimand name: frontdoor
No such variable(s) found!



Running the estimators:

The current estimator: Estimator(name=&#39;backdoor.linear_regression&#39;, params=None)
estimator.params None
linear_regression
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: None, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_matching&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_matching
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_weighting&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_weighting
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dml.DML&#39;, params={&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dr.LinearDRLearner&#39;, params={&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
estimate_values [53.02491896337497, 56.91924177990161, 53.636885678360315, 53.23262282042114, 53.273245506200624]


Running the refuters:

The current refuter: Refuter(name=&#39;dummy_outcome_refuter&#39;, params={&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;})
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
estimated effect [0.5, 0.5, 0.5, 0.5, 0.5]
new_effect [-0.6312168256028098, -0.3792868457551107, 2.334658690330703, -1.145414883431126, 0.8853557411393771]
p_value [0.37925156217988565, 0.38264005612132845, 0.0773380197565436, 0.12514152414934587, 0.42152333891727023]
true value -0.7342836931429669


Running Experiment Number: 3


Current Sample Size: 1000


The current DGP:

        Linear Data Generating Process
        -------------------------------

        treatment:[&#39;t1&#39;]
        outcome:[&#39;y&#39;]
        confounder: [&#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;]
        effect_modifier: [&#39;x1&#39;, &#39;x2&#39;]
        weights: {&#39;confounder=&gt;treatment&#39;: array([[ 9.94368161e+01],
       [-7.15446327e-01],
       [-3.80972789e-03],
       [-5.75703765e-01],
       [ 5.38707893e-01],
       [ 5.75890932e-01]]), &#39;confounder=&gt;outcome&#39;: array([[ 1.00201002e+02],
       [ 9.57540295e-01],
       [ 4.69505864e-02],
       [ 1.27826241e+00],
       [-3.91809312e-01],
       [ 3.95328171e-01]]), &#39;effect_modifier=&gt;outcome&#39;: array([[ 1.19850027],
       [-0.20130359]]), &#39;treatment=&gt;outcome&#39;: array([[-0.73428369]])}
        bias: {&#39;confounder=&gt;treatment&#39;: array([0.27086355]), &#39;confounder=&gt;outcome&#39;: array([0.32207479])}
        seed: None
        treatment_is_binary: True
        percentile: 0.9

printing data shape
(1000, 10)
[0.78315694]
check
printing length of confounder list: 2
printing confounder list: [&#39;w2&#39;, &#39;w3&#39;]
data columns
data columns Index([&#39;x1&#39;, &#39;x2&#39;, &#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;, &#39;t1&#39;, &#39;y&#39;], dtype=&#39;object&#39;)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_dowhy_ranking_methods_11_57.png" src="../_images/example_notebooks_dowhy_ranking_methods_11_57.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
identified_estimand: Estimand type: nonparametric-ate

### Estimand : 1
Estimand name: backdoor
Estimand expression:
  d
─────(Expectation(y|w3,w2))
d[t₁]
Estimand assumption 1, Unconfoundedness: If U→{t1} and U→y then P(y|t1,w3,w2,U) = P(y|t1,w3,w2)

### Estimand : 2
Estimand name: iv
No such variable(s) found!

### Estimand : 3
Estimand name: frontdoor
No such variable(s) found!



Running the estimators:

The current estimator: Estimator(name=&#39;backdoor.linear_regression&#39;, params=None)
estimator.params None
linear_regression
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: None, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_matching&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_matching
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_weighting&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_weighting
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dml.DML&#39;, params={&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dr.LinearDRLearner&#39;, params={&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
estimate_values [57.85581512142886, 52.75026072472895, 57.912781226886864, 50.91874927854064, 57.95184135683232]


Running the refuters:

The current refuter: Refuter(name=&#39;dummy_outcome_refuter&#39;, params={&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;})
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
estimated effect [0.5, 0.5, 0.5, 0.5, 0.5]
new_effect [3.3851812034173827, 3.269845064332407, 2.5336554333210426, 0.7671302927152951, 2.36740710771886]
p_value [2.5116340424867713e-05, 0.10443869363774344, 0.01651518920032031, 0.4391928408976204, 0.16264465758562546]
true value 0.7831569401766588


Running Experiment Number: 4


Current Sample Size: 1000


The current DGP:

        Linear Data Generating Process
        -------------------------------

        treatment:[&#39;t1&#39;]
        outcome:[&#39;y&#39;]
        confounder: [&#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;]
        effect_modifier: [&#39;x1&#39;, &#39;x2&#39;]
        weights: {&#39;confounder=&gt;treatment&#39;: array([[ 9.93109069e+01],
       [ 1.11615133e+00],
       [ 1.01206502e+00],
       [-4.00521173e-02],
       [ 8.93156396e-01],
       [-9.85021405e-01]]), &#39;confounder=&gt;outcome&#39;: array([[99.3172471 ],
       [ 0.64194946],
       [ 0.91875612],
       [ 0.73555063],
       [-1.03988095],
       [-1.42740212]]), &#39;effect_modifier=&gt;outcome&#39;: array([[ 1.16185599],
       [-0.95395208]]), &#39;treatment=&gt;outcome&#39;: array([[0.78315694]])}
        bias: {&#39;confounder=&gt;treatment&#39;: array([-1.64728109]), &#39;confounder=&gt;outcome&#39;: array([0.80945106])}
        seed: None
        treatment_is_binary: True
        percentile: 0.9

printing data shape
(1000, 10)
[1.39882547]
check
printing length of confounder list: 2
printing confounder list: [&#39;w2&#39;, &#39;w3&#39;]
data columns
data columns Index([&#39;x1&#39;, &#39;x2&#39;, &#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;, &#39;t1&#39;, &#39;y&#39;], dtype=&#39;object&#39;)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_dowhy_ranking_methods_11_75.png" src="../_images/example_notebooks_dowhy_ranking_methods_11_75.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
identified_estimand: Estimand type: nonparametric-ate

### Estimand : 1
Estimand name: backdoor
Estimand expression:
  d
─────(Expectation(y|w3,w2))
d[t₁]
Estimand assumption 1, Unconfoundedness: If U→{t1} and U→y then P(y|t1,w3,w2,U) = P(y|t1,w3,w2)

### Estimand : 2
Estimand name: iv
No such variable(s) found!

### Estimand : 3
Estimand name: frontdoor
No such variable(s) found!



Running the estimators:

The current estimator: Estimator(name=&#39;backdoor.linear_regression&#39;, params=None)
estimator.params None
linear_regression
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: None, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_matching&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_matching
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_weighting&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_weighting
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dml.DML&#39;, params={&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dr.LinearDRLearner&#39;, params={&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
estimate_values [64.8745795620197, 70.22942938136646, 67.36206919359368, 61.970660475249154, 65.60254513577934]


Running the refuters:

The current refuter: Refuter(name=&#39;dummy_outcome_refuter&#39;, params={&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;})
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
estimated effect [0.5, 0.5, 0.5, 0.5, 0.5]
new_effect [-0.5354598233639674, 0.33023403629426473, -0.8932909295605125, 0.8026334406770725, 2.6446148500615685]
p_value [0.34695839048374477, 0.43776341280377196, 0.2711518949374593, 0.34151093433358704, 0.31080152913479653]
true value 1.398825466975552


Running Experiment Number: 5


Current Sample Size: 1000


The current DGP:

        Linear Data Generating Process
        -------------------------------

        treatment:[&#39;t1&#39;]
        outcome:[&#39;y&#39;]
        confounder: [&#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;]
        effect_modifier: [&#39;x1&#39;, &#39;x2&#39;]
        weights: {&#39;confounder=&gt;treatment&#39;: array([[ 9.94416874e+01],
       [-6.61703418e-01],
       [-5.42377714e-01],
       [ 5.35719797e-01],
       [-9.67022324e-02],
       [-1.43870091e+00]]), &#39;confounder=&gt;outcome&#39;: array([[99.75787309],
       [ 0.87753278],
       [-0.62815838],
       [-0.71736392],
       [-0.4816274 ],
       [-1.25295718]]), &#39;effect_modifier=&gt;outcome&#39;: array([[ 2.55194361],
       [-1.70495665]]), &#39;treatment=&gt;outcome&#39;: array([[1.39882547]])}
        bias: {&#39;confounder=&gt;treatment&#39;: array([-0.21412013]), &#39;confounder=&gt;outcome&#39;: array([0.9156722])}
        seed: None
        treatment_is_binary: True
        percentile: 0.9

printing data shape
(1000, 10)
[-0.00429042]
check
printing length of confounder list: 2
printing confounder list: [&#39;w2&#39;, &#39;w3&#39;]
data columns
data columns Index([&#39;x1&#39;, &#39;x2&#39;, &#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;, &#39;t1&#39;, &#39;y&#39;], dtype=&#39;object&#39;)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_dowhy_ranking_methods_11_93.png" src="../_images/example_notebooks_dowhy_ranking_methods_11_93.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
identified_estimand: Estimand type: nonparametric-ate

### Estimand : 1
Estimand name: backdoor
Estimand expression:
  d
─────(Expectation(y|w3,w2))
d[t₁]
Estimand assumption 1, Unconfoundedness: If U→{t1} and U→y then P(y|t1,w3,w2,U) = P(y|t1,w3,w2)

### Estimand : 2
Estimand name: iv
No such variable(s) found!

### Estimand : 3
Estimand name: frontdoor
No such variable(s) found!



Running the estimators:

The current estimator: Estimator(name=&#39;backdoor.linear_regression&#39;, params=None)
estimator.params None
linear_regression
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: None, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_matching&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_matching
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_weighting&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_weighting
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dml.DML&#39;, params={&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dr.LinearDRLearner&#39;, params={&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
estimate_values [63.279004451176206, 53.78926361725462, 62.91694818397311, 62.56013623013749, 62.92885166836902]


Running the refuters:

The current refuter: Refuter(name=&#39;dummy_outcome_refuter&#39;, params={&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;})
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
estimated effect [0.5, 0.5, 0.5, 0.5, 0.5]
new_effect [3.447665266466416, 1.9098279313020168, 1.8035830749653683, 0.9496651342314542, 2.5964004381241965]
p_value [0.3025063951534158, 0.3305293077341013, 0.4042463976431008, 0.3531002843656779, 0.05860903301915886]
true value -0.004290416382844565


Running Experiment Number: 6


Current Sample Size: 1000


The current DGP:

        Linear Data Generating Process
        -------------------------------

        treatment:[&#39;t1&#39;]
        outcome:[&#39;y&#39;]
        confounder: [&#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;]
        effect_modifier: [&#39;x1&#39;, &#39;x2&#39;]
        weights: {&#39;confounder=&gt;treatment&#39;: array([[ 1.01183140e+02],
       [ 1.14921597e+00],
       [ 5.11881312e-01],
       [-2.21564265e-01],
       [ 4.38246080e-01],
       [ 3.32377472e-02]]), &#39;confounder=&gt;outcome&#39;: array([[ 9.83881355e+01],
       [ 8.78658056e-01],
       [ 1.66636555e+00],
       [-1.34545495e+00],
       [ 3.70000438e-01],
       [-8.71921976e-02]]), &#39;effect_modifier=&gt;outcome&#39;: array([[-1.22360099],
       [ 0.76260565]]), &#39;treatment=&gt;outcome&#39;: array([[-0.00429042]])}
        bias: {&#39;confounder=&gt;treatment&#39;: array([-0.84036707]), &#39;confounder=&gt;outcome&#39;: array([-0.38788846])}
        seed: None
        treatment_is_binary: True
        percentile: 0.9

printing data shape
(1000, 10)
[-0.15874518]
check
printing length of confounder list: 2
printing confounder list: [&#39;w2&#39;, &#39;w3&#39;]
data columns
data columns Index([&#39;x1&#39;, &#39;x2&#39;, &#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;, &#39;t1&#39;, &#39;y&#39;], dtype=&#39;object&#39;)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_dowhy_ranking_methods_11_111.png" src="../_images/example_notebooks_dowhy_ranking_methods_11_111.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
identified_estimand: Estimand type: nonparametric-ate

### Estimand : 1
Estimand name: backdoor
Estimand expression:
  d
─────(Expectation(y|w3,w2))
d[t₁]
Estimand assumption 1, Unconfoundedness: If U→{t1} and U→y then P(y|t1,w3,w2,U) = P(y|t1,w3,w2)

### Estimand : 2
Estimand name: iv
No such variable(s) found!

### Estimand : 3
Estimand name: frontdoor
No such variable(s) found!



Running the estimators:

The current estimator: Estimator(name=&#39;backdoor.linear_regression&#39;, params=None)
estimator.params None
linear_regression
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: None, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_matching&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_matching
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_weighting&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_weighting
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dml.DML&#39;, params={&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dr.LinearDRLearner&#39;, params={&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
estimate_values [67.7620491179214, 63.22028468463368, 66.04258518745037, 60.03065540537139, 66.80282942584445]


Running the refuters:

The current refuter: Refuter(name=&#39;dummy_outcome_refuter&#39;, params={&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;})
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
estimated effect [0.5, 0.5, 0.5, 0.5, 0.5]
new_effect [1.9148791765089779, 0.49152856021692565, 1.1376836492686007, 1.5697546245267089, -0.8205739472281459]
p_value [0.323354670200794, 0.4990854600033845, 0.3949066311624222, 0.18100986322921142, 0.3243933575540936]
true value -0.15874518166603138


Running Experiment Number: 7


Current Sample Size: 1000


The current DGP:

        Linear Data Generating Process
        -------------------------------

        treatment:[&#39;t1&#39;]
        outcome:[&#39;y&#39;]
        confounder: [&#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;]
        effect_modifier: [&#39;x1&#39;, &#39;x2&#39;]
        weights: {&#39;confounder=&gt;treatment&#39;: array([[101.07667704],
       [ -0.63608279],
       [  0.34550649],
       [  2.03772657],
       [  3.05931256],
       [ -1.02934043]]), &#39;confounder=&gt;outcome&#39;: array([[99.57706028],
       [-1.27692115],
       [-0.37558869],
       [ 1.21111731],
       [-0.45796243],
       [ 0.79212801]]), &#39;effect_modifier=&gt;outcome&#39;: array([[-0.27990308],
       [ 1.80849464]]), &#39;treatment=&gt;outcome&#39;: array([[-0.15874518]])}
        bias: {&#39;confounder=&gt;treatment&#39;: array([-0.51472716]), &#39;confounder=&gt;outcome&#39;: array([0.72273806])}
        seed: None
        treatment_is_binary: True
        percentile: 0.9

printing data shape
(1000, 10)
[-0.15819177]
check
printing length of confounder list: 2
printing confounder list: [&#39;w2&#39;, &#39;w3&#39;]
data columns
data columns Index([&#39;x1&#39;, &#39;x2&#39;, &#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;, &#39;t1&#39;, &#39;y&#39;], dtype=&#39;object&#39;)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_dowhy_ranking_methods_11_129.png" src="../_images/example_notebooks_dowhy_ranking_methods_11_129.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
identified_estimand: Estimand type: nonparametric-ate

### Estimand : 1
Estimand name: backdoor
Estimand expression:
  d
─────(Expectation(y|w3,w2))
d[t₁]
Estimand assumption 1, Unconfoundedness: If U→{t1} and U→y then P(y|t1,w3,w2,U) = P(y|t1,w3,w2)

### Estimand : 2
Estimand name: iv
No such variable(s) found!

### Estimand : 3
Estimand name: frontdoor
No such variable(s) found!



Running the estimators:

The current estimator: Estimator(name=&#39;backdoor.linear_regression&#39;, params=None)
estimator.params None
linear_regression
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: None, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_matching&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_matching
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_weighting&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_weighting
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dml.DML&#39;, params={&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dr.LinearDRLearner&#39;, params={&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
estimate_values [56.252602901678436, 59.186402899022205, 57.44025838070222, 53.31189026537523, 57.16926291365019]


Running the refuters:

The current refuter: Refuter(name=&#39;dummy_outcome_refuter&#39;, params={&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;})
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
estimated effect [0.5, 0.5, 0.5, 0.5, 0.5]
new_effect [-1.8552144131748314, -2.5206320797461266, -1.2088223343125968, -0.5164579455453776, -1.1076629941934506]
p_value [0.10110074037404515, 0.2664189068095596, 0.1972005460223345, 0.33503112661829637, 0.26703745935256207]
true value -0.15819176623273284


Running Experiment Number: 8


Current Sample Size: 1000


The current DGP:

        Linear Data Generating Process
        -------------------------------

        treatment:[&#39;t1&#39;]
        outcome:[&#39;y&#39;]
        confounder: [&#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;]
        effect_modifier: [&#39;x1&#39;, &#39;x2&#39;]
        weights: {&#39;confounder=&gt;treatment&#39;: array([[98.93613393],
       [-0.13665447],
       [-0.30895418],
       [-1.99227529],
       [ 0.23114732],
       [ 1.14712176]]), &#39;confounder=&gt;outcome&#39;: array([[99.88579859],
       [ 1.56499414],
       [ 0.21082804],
       [-0.28654916],
       [ 1.43998328],
       [ 0.22607824]]), &#39;effect_modifier=&gt;outcome&#39;: array([[-0.02204782],
       [ 0.60368778]]), &#39;treatment=&gt;outcome&#39;: array([[-0.15819177]])}
        bias: {&#39;confounder=&gt;treatment&#39;: array([0.43147235]), &#39;confounder=&gt;outcome&#39;: array([0.00166011])}
        seed: None
        treatment_is_binary: True
        percentile: 0.9

printing data shape
(1000, 10)
[0.64984708]
check
printing length of confounder list: 2
printing confounder list: [&#39;w2&#39;, &#39;w3&#39;]
data columns
data columns Index([&#39;x1&#39;, &#39;x2&#39;, &#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;, &#39;t1&#39;, &#39;y&#39;], dtype=&#39;object&#39;)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_dowhy_ranking_methods_11_148.png" src="../_images/example_notebooks_dowhy_ranking_methods_11_148.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
identified_estimand: Estimand type: nonparametric-ate

### Estimand : 1
Estimand name: backdoor
Estimand expression:
  d
─────(Expectation(y|w3,w2))
d[t₁]
Estimand assumption 1, Unconfoundedness: If U→{t1} and U→y then P(y|t1,w3,w2,U) = P(y|t1,w3,w2)

### Estimand : 2
Estimand name: iv
No such variable(s) found!

### Estimand : 3
Estimand name: frontdoor
No such variable(s) found!



Running the estimators:

The current estimator: Estimator(name=&#39;backdoor.linear_regression&#39;, params=None)
estimator.params None
linear_regression
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: None, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_matching&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_matching
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_weighting&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_weighting
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dml.DML&#39;, params={&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dr.LinearDRLearner&#39;, params={&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
estimate_values [68.50631910021632, 77.28400324344548, 70.3957481863207, 62.88513455705642, 68.5125558157075]


Running the refuters:

The current refuter: Refuter(name=&#39;dummy_outcome_refuter&#39;, params={&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;})
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
estimated effect [0.5, 0.5, 0.5, 0.5, 0.5]
new_effect [0.45597698778950424, -1.9932988393340143, -1.1609534377462754, -2.952967386674657e-16, -3.2001418165854494]
p_value [0.49240743338828086, 0.0031491004113481935, 0.3616770952393019, 0.0, 0.027355864480536396]
true value 0.6498470815943337


Running Experiment Number: 9


Current Sample Size: 1000


The current DGP:

        Linear Data Generating Process
        -------------------------------

        treatment:[&#39;t1&#39;]
        outcome:[&#39;y&#39;]
        confounder: [&#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;]
        effect_modifier: [&#39;x1&#39;, &#39;x2&#39;]
        weights: {&#39;confounder=&gt;treatment&#39;: array([[99.22529231],
       [-1.19227202],
       [ 0.72908529],
       [-0.34284713],
       [ 0.21196776],
       [-0.82985599]]), &#39;confounder=&gt;outcome&#39;: array([[98.23906319],
       [ 0.63395556],
       [ 0.470546  ],
       [-0.87296459],
       [ 1.16944262],
       [-0.71531251]]), &#39;effect_modifier=&gt;outcome&#39;: array([[1.3090193 ],
       [0.66136274]]), &#39;treatment=&gt;outcome&#39;: array([[0.64984708]])}
        bias: {&#39;confounder=&gt;treatment&#39;: array([0.25813396]), &#39;confounder=&gt;outcome&#39;: array([0.26455714])}
        seed: None
        treatment_is_binary: True
        percentile: 0.9

printing data shape
(1000, 10)
[1.04303247]
check
printing length of confounder list: 2
printing confounder list: [&#39;w2&#39;, &#39;w3&#39;]
data columns
data columns Index([&#39;x1&#39;, &#39;x2&#39;, &#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;, &#39;t1&#39;, &#39;y&#39;], dtype=&#39;object&#39;)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_dowhy_ranking_methods_11_166.png" src="../_images/example_notebooks_dowhy_ranking_methods_11_166.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
identified_estimand: Estimand type: nonparametric-ate

### Estimand : 1
Estimand name: backdoor
Estimand expression:
  d
─────(Expectation(y|w3,w2))
d[t₁]
Estimand assumption 1, Unconfoundedness: If U→{t1} and U→y then P(y|t1,w3,w2,U) = P(y|t1,w3,w2)

### Estimand : 2
Estimand name: iv
No such variable(s) found!

### Estimand : 3
Estimand name: frontdoor
No such variable(s) found!



Running the estimators:

The current estimator: Estimator(name=&#39;backdoor.linear_regression&#39;, params=None)
estimator.params None
linear_regression
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: None, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_matching&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_matching
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_weighting&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_weighting
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dml.DML&#39;, params={&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dr.LinearDRLearner&#39;, params={&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
estimate_values [69.15035465187597, 82.3626100200028, 68.08979141355687, 78.37691995003675, 67.83204291463188]


Running the refuters:

The current refuter: Refuter(name=&#39;dummy_outcome_refuter&#39;, params={&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;})
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
estimated effect [0.5, 0.5, 0.5, 0.5, 0.5]
new_effect [-0.14044711997376796, -0.36566638003095453, 1.240619299645757, 0.38962243159035986, -1.267177719334987]
p_value [0.44627916755173636, 0.38904861092743503, 0.38250380150687746, 0.4597916231574046, 0.16966320266505908]
true value 1.043032467929503


Completed all experiments. Saving the data...
Data has been saved in  results/Test_1_2022-03-20_data.csv
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#PLOT</span>
<span class="c1">#This plot shows the Mean Absolute Error of the Orginal Estimate from the true value and of the New Effect from</span>
<span class="c1">#the expected value for each estimator.</span>
<span class="n">plot_MAEs</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_dowhy_ranking_methods_12_0.png" src="../_images/example_notebooks_dowhy_ranking_methods_12_0.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Printing MAE of various estimates:
ORIGINAL_ESTIMATE:backdoor.propensity_score_matching 63.95603867153549
ORIGINAL_ESTIMATE:backdoor.econml.dr.LinearDRLearner 62.95055296158965
ORIGINAL_ESTIMATE:backdoor.linear_regression 62.85628558899655
ORIGINAL_ESTIMATE:backdoor.econml.dml.DML 58.46323930340628
dummy_outcome_refuter:backdoor.econml.dr.LinearDRLearner:NEW_EFFECT 2.0759501696845177
dummy_outcome_refuter:backdoor.linear_regression:NEW_EFFECT 1.8238520901753095
dummy_outcome_refuter:backdoor.propensity_score_weighting:NEW_EFFECT 1.690312986216254
dummy_outcome_refuter:backdoor.propensity_score_matching:NEW_EFFECT 1.4511912092165176
dummy_outcome_refuter:backdoor.propensity_score_matching:P_VALUE 0.8969232299327585
dummy_outcome_refuter:backdoor.econml.dr.LinearDRLearner:P_VALUE 0.889538213727097
dummy_outcome_refuter:backdoor.linear_regression:ESTIMATED_EFFECT 0.8733632861818805
dummy_outcome_refuter:backdoor.propensity_score_matching:ESTIMATED_EFFECT 0.8733632861818805
dummy_outcome_refuter:backdoor.propensity_score_weighting:ESTIMATED_EFFECT 0.8733632861818805
dummy_outcome_refuter:backdoor.econml.dml.DML:ESTIMATED_EFFECT 0.8733632861818805
dummy_outcome_refuter:backdoor.econml.dr.LinearDRLearner:ESTIMATED_EFFECT 0.8733632861818805
dummy_outcome_refuter:backdoor.propensity_score_weighting:P_VALUE 0.8475780448843704
dummy_outcome_refuter:backdoor.linear_regression:P_VALUE 0.8078740676719918
dummy_outcome_refuter:backdoor.econml.dml.DML:NEW_EFFECT 0.76307416995171
dummy_outcome_refuter:backdoor.econml.dml.DML:P_VALUE 0.7629193621343455
</pre></div></div>
</div>
<section id="Ranking-based-on-Original-Estimate">
<h2>Ranking based on Original Estimate<a class="headerlink" href="#Ranking-based-on-Original-Estimate" title="Permalink to this headline"></a></h2>
<p>The Original Estimate is calculated in the presence of the True Value (that is, the ground truth). However in many real life datasets, the ground truth may not be known. Hence, we want the ranking produced by our refutation tests to be in coherence with that obtained from the Original Estimates. According to the Original Estimate values, the ranking of the estimators should be as follows (the method with the least MAE should get the best rank): 1. DMLCateEstimator 2. LinearRegression 3.
LinearDRLearner 4. Propensity Score Matching</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">estimator_list</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;backdoor.linear_regression&quot;</span><span class="p">,</span>
                  <span class="c1">#&quot;backdoor.propensity_score_stratification&quot;,</span>
                  <span class="s2">&quot;backdoor.propensity_score_matching&quot;</span><span class="p">,</span>
                  <span class="s2">&quot;backdoor.econml.dml.DML&quot;</span><span class="p">,</span>
                  <span class="s2">&quot;backdoor.econml.dr.LinearDRLearner&quot;</span><span class="p">,</span>
                  <span class="c1">#&quot;backdoor.econml.metalearners.TLearner&quot;,</span>
                  <span class="c1">#&quot;backdoor.econml.metalearners.XLearner&quot;,</span>
                  <span class="c1">#&quot;backdoor.causalml.inference.meta.LRSRegressor&quot;,</span>
                  <span class="c1">#&quot;backdoor.causalml.inference.meta.XGBTRegressor&quot;,</span>
                  <span class="c1">#&quot;backdoor.causalml.inference.meta.MLPTRegressor&quot;,</span>
                  <span class="c1">#&quot;backdoor.causalml.inference.meta.BaseXRegressor&quot;</span>
                <span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#This plot shows the deviation of the original estimate, the new effect and the estimated effect from the true value</span>
<span class="n">refuter</span> <span class="o">=</span> <span class="s1">&#39;dummy_outcome_refuter&#39;</span>
<span class="n">deviation_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">estimator</span> <span class="ow">in</span> <span class="n">estimator_list</span><span class="p">:</span>
    <span class="n">plot_estimators_and_refuters</span><span class="p">(</span><span class="n">refuter</span><span class="p">,</span> <span class="n">estimator</span><span class="p">)</span>
    <span class="n">avg_deviation</span> <span class="o">=</span> <span class="p">((</span><span class="n">res</span><span class="p">[</span><span class="n">refuter</span><span class="o">+</span><span class="s1">&#39;:&#39;</span><span class="o">+</span><span class="n">estimator</span><span class="o">+</span><span class="s1">&#39;:NEW_EFFECT&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">avg_deviation</span><span class="p">)</span>
    <span class="n">deviation_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">avg_deviation</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_dowhy_ranking_methods_16_0.png" src="../_images/example_notebooks_dowhy_ranking_methods_16_0.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
6.745179241632404
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_dowhy_ranking_methods_16_2.png" src="../_images/example_notebooks_dowhy_ranking_methods_16_2.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
-0.43774988246850527
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_dowhy_ranking_methods_16_4.png" src="../_images/example_notebooks_dowhy_ranking_methods_16_4.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
2.277086428462142
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_dowhy_ranking_methods_16_6.png" src="../_images/example_notebooks_dowhy_ranking_methods_16_6.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
5.232594590444256
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;Figure size 432x288 with 0 Axes&gt;
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_deviations</span><span class="p">(</span><span class="n">estimator_list</span><span class="p">,</span> <span class="n">deviation_list</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">estimator_list</span><span class="p">)):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">estimator_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span><span class="s2">&quot;: &quot;</span><span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">deviation_list</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_dowhy_ranking_methods_17_0.png" src="../_images/example_notebooks_dowhy_ranking_methods_17_0.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
backdoor.linear_regression: 6.745179241632404
backdoor.propensity_score_matching: -0.43774988246850527
backdoor.econml.dml.DML: 2.277086428462142
backdoor.econml.dr.LinearDRLearner: 5.232594590444256
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">estimator_list</span><span class="p">,</span> <span class="n">deviation_list</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">item</span><span class="p">:</span> <span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)}</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;backdoor.linear_regression&#39;: 6.745179241632404,
 &#39;backdoor.econml.dr.LinearDRLearner&#39;: 5.232594590444256,
 &#39;backdoor.econml.dml.DML&#39;: 2.277086428462142,
 &#39;backdoor.propensity_score_matching&#39;: -0.43774988246850527}
</pre></div></div>
</div>
</section>
<section id="Ranking-based-on-New-Effect-(Refutatation-results)">
<h2>Ranking based on New Effect (Refutatation results)<a class="headerlink" href="#Ranking-based-on-New-Effect-(Refutatation-results)" title="Permalink to this headline"></a></h2>
<p>The ranking based on absolute value of deviations is : 1. Propensity Score Matching 2. Linear DR Learner 3. DML CATE Estimator 4. Linear Regression</p>
<p>Clearly, the observed unmodelled confounding error is not able to match the ranking based on the Original Estimate. It is not even able to tell that the clear winner amongst the methods according to the true value is DML CATE Estimator</p>
</section>
</section>
<section id="Unobserved-confounding-error">
<h1>Unobserved confounding error<a class="headerlink" href="#Unobserved-confounding-error" title="Permalink to this headline"></a></h1>
<p>For each estimator, we now simulate unobserved confounders and check its effect using dummy outcome refuter to check the unobserved confounding error for each estimator. That is, we run the refutation test for each estimator not only on the observed confounder, but also on an unobserved confounder that we simulate using the AddUnobservedCommonCause class and analyse whether there is a strong confounder that is unobserved (missing) and needs to be accounted for.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">unobserved_confounding_error</span> <span class="o">=</span> <span class="n">Experiment</span><span class="p">(</span>
    <span class="n">experiment_name</span><span class="o">=</span><span class="s1">&#39;Test&#39;</span><span class="p">,</span>
    <span class="n">experiment_id</span><span class="o">=</span><span class="s1">&#39;2&#39;</span><span class="p">,</span>
    <span class="n">num_experiments</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="c1"># 10</span>
    <span class="n">sample_sizes</span><span class="o">=</span><span class="n">sample_size</span><span class="p">,</span>
    <span class="n">dgps</span><span class="o">=</span><span class="n">dgp_list</span><span class="p">,</span>
    <span class="n">estimators</span><span class="o">=</span><span class="n">estimator_tuples</span><span class="p">,</span>
    <span class="n">refuters</span><span class="o">=</span><span class="n">refuter_tuples</span><span class="p">,</span>
    <span class="n">simulate_unobserved_confounding</span> <span class="o">=</span> <span class="kc">True</span>
<span class="p">)</span>

<span class="c1"># Run the experiment</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">unobserved_confounding_error</span><span class="o">.</span><span class="n">experiment</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>


Running Experiment: Test_2


Running Experiment Number: 0


Current Sample Size: 1000


The current DGP:

        Linear Data Generating Process
        -------------------------------

        treatment:[&#39;t1&#39;]
        outcome:[&#39;y&#39;]
        confounder: [&#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;]
        effect_modifier: [&#39;x1&#39;, &#39;x2&#39;]
        weights: {&#39;confounder=&gt;treatment&#39;: array([[100.55362103],
       [  0.80865123],
       [  0.10190771],
       [ -0.62721069],
       [ -0.35094311],
       [ -2.44162526]]), &#39;confounder=&gt;outcome&#39;: array([[99.59531576],
       [ 0.54925049],
       [-0.36750016],
       [ 0.39619088],
       [ 0.53832704],
       [-0.66683889]]), &#39;effect_modifier=&gt;outcome&#39;: array([[-0.55616212],
       [ 0.38279384]]), &#39;treatment=&gt;outcome&#39;: array([[1.04303247]])}
        bias: {&#39;confounder=&gt;treatment&#39;: array([0.42138045]), &#39;confounder=&gt;outcome&#39;: array([-0.21332967])}
        seed: None
        treatment_is_binary: True
        percentile: 0.9

printing data shape
(1000, 10)
[1.56367264]
check
printing length of confounder list: 2
printing confounder list: [&#39;w2&#39;, &#39;w3&#39;]
data columns
data columns Index([&#39;x1&#39;, &#39;x2&#39;, &#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;, &#39;t1&#39;, &#39;y&#39;], dtype=&#39;object&#39;)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_dowhy_ranking_methods_24_1.png" src="../_images/example_notebooks_dowhy_ranking_methods_24_1.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
identified_estimand: Estimand type: nonparametric-ate

### Estimand : 1
Estimand name: backdoor
Estimand expression:
  d
─────(Expectation(y|w3,w2))
d[t₁]
Estimand assumption 1, Unconfoundedness: If U→{t1} and U→y then P(y|t1,w3,w2,U) = P(y|t1,w3,w2)

### Estimand : 2
Estimand name: iv
No such variable(s) found!

### Estimand : 3
Estimand name: frontdoor
No such variable(s) found!



Running the estimators:

The current estimator: Estimator(name=&#39;backdoor.linear_regression&#39;, params=None)
estimator.params None
linear_regression
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: None, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_matching&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_matching
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_weighting&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_weighting
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dml.DML&#39;, params={&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dr.LinearDRLearner&#39;, params={&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
estimate_values [82.57904829697335, 93.63990506055599, 82.5581575994953, 78.07510673373824, 82.79345728189568]


Running the refuters:

The current refuter: Refuter(name=&#39;dummy_outcome_refuter&#39;, params={&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;})
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9cb11a60&gt;
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0      -268.102259
1      3091.311932
2      1398.889764
3      1906.414723
4     -1634.691994
          ...
995    -459.991578
996    -884.043640
997    -827.897044
998   -1366.402664
999    2996.614946
Length: 1000, dtype: float64}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9c808f10&gt;
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0      -268.151247
1      3090.802445
2      1395.389292
3      1908.497667
4     -1633.882687
          ...
995    -458.216362
996    -884.371144
997    -825.794956
998   -1365.605934
999    2997.683638
Length: 1000, dtype: float64}
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9c808eb0&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0      -268.620654
1      3093.285800
2      1399.364167
3      1907.465249
4     -1633.873327
          ...
995    -458.920344
996    -883.979928
997    -826.369294
998   -1364.700545
999    2998.720814
Length: 1000, dtype: float64}
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9c810b80&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0      -266.597240
1      3091.324597
2      1397.881283
3      1907.405168
4     -1634.397994
          ...
995    -458.401721
996    -884.597366
997    -828.735957
998   -1365.811653
999    2995.996732
Length: 1000, dtype: float64}
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9c810d30&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0      -267.890716
1      3091.997547
2      1399.174580
3      1907.015313
4     -1633.799535
          ...
995    -459.014984
996    -882.639123
997    -828.173283
998   -1365.835262
999    2997.469493
Length: 1000, dtype: float64}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
estimated effect [0.5, 0.5, 0.5, 0.5, 0.5]
new_effect [11.30390040811936, 7.2514362614062176, 5.148653183307322, 5.973775727522197, 6.557428998297622]
p_value [0.04236180908722596, 0.2394678006358314, 0.3419151700026071, 0.2880393354199367, 0.33865078200653753]
true value 1.5636726375285916


Running Experiment Number: 1


Current Sample Size: 1000


The current DGP:

        Linear Data Generating Process
        -------------------------------

        treatment:[&#39;t1&#39;]
        outcome:[&#39;y&#39;]
        confounder: [&#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;]
        effect_modifier: [&#39;x1&#39;, &#39;x2&#39;]
        weights: {&#39;confounder=&gt;treatment&#39;: array([[100.54354783],
       [ -1.10109153],
       [  1.13004916],
       [  0.18463799],
       [ -1.90103601],
       [  0.5248941 ]]), &#39;confounder=&gt;outcome&#39;: array([[98.93512425],
       [ 1.92267036],
       [ 2.86500951],
       [ 0.54743181],
       [-1.21092165],
       [-0.32904593]]), &#39;effect_modifier=&gt;outcome&#39;: array([[ 0.69668849],
       [-1.05356427]]), &#39;treatment=&gt;outcome&#39;: array([[1.56367264]])}
        bias: {&#39;confounder=&gt;treatment&#39;: array([-0.18079193]), &#39;confounder=&gt;outcome&#39;: array([-0.18324012])}
        seed: None
        treatment_is_binary: True
        percentile: 0.9

printing data shape
(1000, 10)
[-1.62700825]
check
printing length of confounder list: 2
printing confounder list: [&#39;w2&#39;, &#39;w3&#39;]
data columns
data columns Index([&#39;x1&#39;, &#39;x2&#39;, &#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;, &#39;t1&#39;, &#39;y&#39;], dtype=&#39;object&#39;)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_dowhy_ranking_methods_24_22.png" src="../_images/example_notebooks_dowhy_ranking_methods_24_22.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
identified_estimand: Estimand type: nonparametric-ate

### Estimand : 1
Estimand name: backdoor
Estimand expression:
  d
─────(Expectation(y|w3,w2))
d[t₁]
Estimand assumption 1, Unconfoundedness: If U→{t1} and U→y then P(y|t1,w3,w2,U) = P(y|t1,w3,w2)

### Estimand : 2
Estimand name: iv
No such variable(s) found!

### Estimand : 3
Estimand name: frontdoor
No such variable(s) found!



Running the estimators:

The current estimator: Estimator(name=&#39;backdoor.linear_regression&#39;, params=None)
estimator.params None
linear_regression
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: None, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_matching&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_matching
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_weighting&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_weighting
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dml.DML&#39;, params={&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dr.LinearDRLearner&#39;, params={&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
estimate_values [49.55964047801915, 51.367130780855085, 49.92143094046169, 51.43511986456838, 49.66232181536997]


Running the refuters:

The current refuter: Refuter(name=&#39;dummy_outcome_refuter&#39;, params={&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0      -267.890716
1      3091.997547
2      1399.174580
3      1907.015313
4     -1633.799535
          ...
995    -459.014984
996    -882.639123
997    -828.173283
998   -1365.835262
999    2997.469493
Length: 1000, dtype: float64})
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9c7b86d0&gt;
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0       265.134810
1       809.970030
2      3512.900223
3     -4536.463784
4      1015.789070
          ...
995    1161.056096
996    -485.198700
997    1351.417536
998      93.279739
999     607.701416
Length: 1000, dtype: float64}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9cb06af0&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0       267.428743
1       809.468396
2      3511.478441
3     -4536.347058
4      1016.933928
          ...
995    1160.889728
996    -485.292278
997    1351.144550
998      91.952575
999     606.944508
Length: 1000, dtype: float64}
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9c8d1a60&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0       264.924299
1       811.213176
2      3511.389590
3     -4535.434775
4      1013.996081
          ...
995    1160.590486
996    -486.946988
997    1351.640778
998      92.064070
999     606.820929
Length: 1000, dtype: float64}
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9cc33220&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0       266.635353
1       811.026148
2      3511.300958
3     -4535.724388
4      1016.106109
          ...
995    1159.814182
996    -486.408294
997    1351.932320
998      94.231902
999     606.698151
Length: 1000, dtype: float64}
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7fb158524070&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0       265.032114
1       810.302681
2      3513.674359
3     -4535.997667
4      1015.819598
          ...
995    1160.272864
996    -485.407186
997    1350.859644
998      93.686024
999     605.430731
Length: 1000, dtype: float64}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
estimated effect [0.5, 0.5, 0.5, 0.5, 0.5]
new_effect [2.1446462879373946, 4.257267259892182, 9.401254104281696, 4.752016770850927, 15.937872004763426]
p_value [0.4067308937177251, 0.1401787129642681, 0.10914223970963444, 0.22905922404475193, 0.031650729690582295]
true value -1.627008250669471


Running Experiment Number: 2


Current Sample Size: 1000


The current DGP:

        Linear Data Generating Process
        -------------------------------

        treatment:[&#39;t1&#39;]
        outcome:[&#39;y&#39;]
        confounder: [&#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;]
        effect_modifier: [&#39;x1&#39;, &#39;x2&#39;]
        weights: {&#39;confounder=&gt;treatment&#39;: array([[ 9.93760425e+01],
       [ 7.43586117e-01],
       [-1.29875835e+00],
       [ 1.54181089e+00],
       [-2.03854116e-01],
       [-1.66556191e-02]]), &#39;confounder=&gt;outcome&#39;: array([[100.06820301],
       [  0.53261228],
       [  0.56935313],
       [ -1.14782919],
       [  1.58762278],
       [  0.55576657]]), &#39;effect_modifier=&gt;outcome&#39;: array([[0.37262017],
       [0.23713719]]), &#39;treatment=&gt;outcome&#39;: array([[-1.62700825]])}
        bias: {&#39;confounder=&gt;treatment&#39;: array([1.52798611]), &#39;confounder=&gt;outcome&#39;: array([0.96775565])}
        seed: None
        treatment_is_binary: True
        percentile: 0.9

printing data shape
(1000, 10)
[-0.4202084]
check
printing length of confounder list: 2
printing confounder list: [&#39;w2&#39;, &#39;w3&#39;]
data columns
data columns Index([&#39;x1&#39;, &#39;x2&#39;, &#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;, &#39;t1&#39;, &#39;y&#39;], dtype=&#39;object&#39;)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_dowhy_ranking_methods_24_40.png" src="../_images/example_notebooks_dowhy_ranking_methods_24_40.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
identified_estimand: Estimand type: nonparametric-ate

### Estimand : 1
Estimand name: backdoor
Estimand expression:
  d
─────(Expectation(y|w3,w2))
d[t₁]
Estimand assumption 1, Unconfoundedness: If U→{t1} and U→y then P(y|t1,w3,w2,U) = P(y|t1,w3,w2)

### Estimand : 2
Estimand name: iv
No such variable(s) found!

### Estimand : 3
Estimand name: frontdoor
No such variable(s) found!



Running the estimators:

The current estimator: Estimator(name=&#39;backdoor.linear_regression&#39;, params=None)
estimator.params None
linear_regression
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: None, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_matching&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_matching
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_weighting&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_weighting
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dml.DML&#39;, params={&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dr.LinearDRLearner&#39;, params={&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
estimate_values [67.19561078333993, 70.79713681972358, 67.73996817383382, 62.88012984898532, 67.07217375148059]


Running the refuters:

The current refuter: Refuter(name=&#39;dummy_outcome_refuter&#39;, params={&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0       265.032114
1       810.302681
2      3513.674359
3     -4535.997667
4      1015.819598
          ...
995    1160.272864
996    -485.407186
997    1350.859644
998      93.686024
999     605.430731
Length: 1000, dtype: float64})
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9c810df0&gt;
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0       466.556203
1      2863.821682
2     -1255.470804
3      2192.293127
4     -2855.904083
          ...
995    1861.669596
996   -2753.088690
997    -823.615312
998    1494.528626
999   -1363.490158
Length: 1000, dtype: float64}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9cc47160&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0       465.001851
1      2863.734166
2     -1256.524496
3      2189.868904
4     -2854.501088
          ...
995    1862.044258
996   -2754.766929
997    -824.061384
998    1495.568766
999   -1363.678288
Length: 1000, dtype: float64}
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9c861df0&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0       464.367805
1      2863.783377
2     -1254.707072
3      2191.978203
4     -2854.373325
          ...
995    1859.741023
996   -2754.931639
997    -827.883951
998    1496.939678
999   -1365.608848
Length: 1000, dtype: float64}
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9c710c40&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0       465.841492
1      2862.029171
2     -1255.817741
3      2189.992532
4     -2854.524051
          ...
995    1859.503740
996   -2754.024346
997    -825.217256
998    1495.232540
999   -1363.829431
Length: 1000, dtype: float64}
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9c4d5340&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0       464.656448
1      2863.167235
2     -1255.379718
3      2189.528106
4     -2856.010038
          ...
995    1861.813882
996   -2751.412013
997    -825.332070
998    1496.842499
999   -1363.710477
Length: 1000, dtype: float64}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
estimated effect [0.5, 0.5, 0.5, 0.5, 0.5]
new_effect [4.462754105032427, -0.4947801315473127, 4.513385645928362, 3.834260683137895, 1.046773869527649]
p_value [0.2864901558800753, 0.45334264371756705, 0.28881703795250546, 0.2592161428256232, 0.4741912125991398]
true value -0.4202083982914195


Running Experiment Number: 3


Current Sample Size: 1000


The current DGP:

        Linear Data Generating Process
        -------------------------------

        treatment:[&#39;t1&#39;]
        outcome:[&#39;y&#39;]
        confounder: [&#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;]
        effect_modifier: [&#39;x1&#39;, &#39;x2&#39;]
        weights: {&#39;confounder=&gt;treatment&#39;: array([[100.138395  ],
       [  0.66779692],
       [ -1.2675515 ],
       [ -0.71442687],
       [  0.57138894],
       [ -1.32973298]]), &#39;confounder=&gt;outcome&#39;: array([[98.71261124],
       [ 0.28977117],
       [ 1.26208023],
       [ 0.82552492],
       [ 1.50654411],
       [-0.57610066]]), &#39;effect_modifier=&gt;outcome&#39;: array([[-0.33630862],
       [ 0.34746437]]), &#39;treatment=&gt;outcome&#39;: array([[-0.4202084]])}
        bias: {&#39;confounder=&gt;treatment&#39;: array([-0.21887475]), &#39;confounder=&gt;outcome&#39;: array([0.60774375])}
        seed: None
        treatment_is_binary: True
        percentile: 0.9

printing data shape
(1000, 10)
[0.27183045]
check
printing length of confounder list: 2
printing confounder list: [&#39;w2&#39;, &#39;w3&#39;]
data columns
data columns Index([&#39;x1&#39;, &#39;x2&#39;, &#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;, &#39;t1&#39;, &#39;y&#39;], dtype=&#39;object&#39;)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_dowhy_ranking_methods_24_59.png" src="../_images/example_notebooks_dowhy_ranking_methods_24_59.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
identified_estimand: Estimand type: nonparametric-ate

### Estimand : 1
Estimand name: backdoor
Estimand expression:
  d
─────(Expectation(y|w3,w2))
d[t₁]
Estimand assumption 1, Unconfoundedness: If U→{t1} and U→y then P(y|t1,w3,w2,U) = P(y|t1,w3,w2)

### Estimand : 2
Estimand name: iv
No such variable(s) found!

### Estimand : 3
Estimand name: frontdoor
No such variable(s) found!



Running the estimators:

The current estimator: Estimator(name=&#39;backdoor.linear_regression&#39;, params=None)
estimator.params None
linear_regression
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: None, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_matching&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_matching
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_weighting&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_weighting
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dml.DML&#39;, params={&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dr.LinearDRLearner&#39;, params={&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
estimate_values [62.7448822622582, 66.63537490673737, 62.46733098115639, 63.44246092774517, 62.28808039532347]


Running the refuters:

The current refuter: Refuter(name=&#39;dummy_outcome_refuter&#39;, params={&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0       464.656448
1      2863.167235
2     -1255.379718
3      2189.528106
4     -2856.010038
          ...
995    1861.813882
996   -2751.412013
997    -825.332070
998    1496.842499
999   -1363.710477
Length: 1000, dtype: float64})
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9c534c40&gt;
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0      1869.029294
1      3401.375293
2      1942.926265
3     -3801.125795
4     -3019.372727
          ...
995    1113.660287
996   -1202.159275
997   -1875.016986
998      99.571599
999    1027.924472
Length: 1000, dtype: float64}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9c734cd0&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0      1869.890273
1      3401.296647
2      1942.437718
3     -3802.087690
4     -3020.266252
          ...
995    1115.378988
996   -1201.856863
997   -1876.193767
998      99.219599
999    1028.403770
Length: 1000, dtype: float64}
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9ca03f40&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0      1869.610640
1      3404.556750
2      1943.933786
3     -3802.266158
4     -3019.656011
          ...
995    1114.736714
996   -1201.835922
997   -1875.649029
998     100.017013
999    1028.694692
Length: 1000, dtype: float64}
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9c707370&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0      1870.114071
1      3402.784173
2      1941.715690
3     -3802.576350
4     -3020.859757
          ...
995    1114.450307
996   -1202.588853
997   -1875.906430
998      99.830145
999    1027.202221
Length: 1000, dtype: float64}
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9c808f40&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0      1868.129316
1      3402.582614
2      1943.931593
3     -3801.185153
4     -3019.064127
          ...
995    1115.692724
996   -1200.601991
997   -1876.748004
998     100.267132
999    1029.007004
Length: 1000, dtype: float64}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
estimated effect [0.5, 0.5, 0.5, 0.5, 0.5]
new_effect [6.489465392615839, 10.824421828940638, 8.908603546818231, 4.734079531626364, 3.9068725343098563]
p_value [0.02940551072172958, 0.0702199961878823, 0.19240399183180967, 0.32736842656691345, 0.32904330447762004]
true value 0.2718304546729197


Running Experiment Number: 4


Current Sample Size: 1000


The current DGP:

        Linear Data Generating Process
        -------------------------------

        treatment:[&#39;t1&#39;]
        outcome:[&#39;y&#39;]
        confounder: [&#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;]
        effect_modifier: [&#39;x1&#39;, &#39;x2&#39;]
        weights: {&#39;confounder=&gt;treatment&#39;: array([[ 9.81836692e+01],
       [ 2.47760129e+00],
       [ 1.76438663e+00],
       [-6.29048821e-02],
       [ 2.09878460e-01],
       [ 1.31466851e-01]]), &#39;confounder=&gt;outcome&#39;: array([[102.21977097],
       [ -0.77804449],
       [  1.52180316],
       [ -0.832457  ],
       [  1.12175011],
       [  0.66941335]]), &#39;effect_modifier=&gt;outcome&#39;: array([[-0.79375323],
       [-1.14806867]]), &#39;treatment=&gt;outcome&#39;: array([[0.27183045]])}
        bias: {&#39;confounder=&gt;treatment&#39;: array([1.33852675]), &#39;confounder=&gt;outcome&#39;: array([0.2631223])}
        seed: None
        treatment_is_binary: True
        percentile: 0.9

printing data shape
(1000, 10)
[1.07747938]
check
printing length of confounder list: 2
printing confounder list: [&#39;w2&#39;, &#39;w3&#39;]
data columns
data columns Index([&#39;x1&#39;, &#39;x2&#39;, &#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;, &#39;t1&#39;, &#39;y&#39;], dtype=&#39;object&#39;)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_dowhy_ranking_methods_24_76.png" src="../_images/example_notebooks_dowhy_ranking_methods_24_76.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
identified_estimand: Estimand type: nonparametric-ate

### Estimand : 1
Estimand name: backdoor
Estimand expression:
  d
─────(Expectation(y|w3,w2))
d[t₁]
Estimand assumption 1, Unconfoundedness: If U→{t1} and U→y then P(y|t1,w3,w2,U) = P(y|t1,w3,w2)

### Estimand : 2
Estimand name: iv
No such variable(s) found!

### Estimand : 3
Estimand name: frontdoor
No such variable(s) found!



Running the estimators:

The current estimator: Estimator(name=&#39;backdoor.linear_regression&#39;, params=None)
estimator.params None
linear_regression
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: None, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_matching&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_matching
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_weighting&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_weighting
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dml.DML&#39;, params={&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dr.LinearDRLearner&#39;, params={&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
estimate_values [54.68209415512192, 48.599747885313135, 50.938840877227804, 43.53688127533345, 54.96246023676153]


Running the refuters:

The current refuter: Refuter(name=&#39;dummy_outcome_refuter&#39;, params={&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0      1868.129316
1      3402.582614
2      1943.931593
3     -3801.185153
4     -3019.064127
          ...
995    1115.692724
996   -1200.601991
997   -1876.748004
998     100.267132
999    1029.007004
Length: 1000, dtype: float64})
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9c79b9a0&gt;
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0      -611.560422
1      2085.175870
2      -359.133510
3      -923.211230
4       302.582739
          ...
995     101.228197
996    -778.128544
997    2141.122737
998   -3295.688809
999   -2029.440126
Length: 1000, dtype: float64}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9c534d30&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0      -610.960719
1      2083.271681
2      -356.443012
3      -922.373158
4       301.537120
          ...
995     104.384315
996    -777.344325
997    2141.267271
998   -3297.735984
999   -2029.186324
Length: 1000, dtype: float64}
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9c534f70&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0      -611.641307
1      2084.513652
2      -359.304616
3      -922.191436
4       301.659034
          ...
995     104.158687
996    -777.633983
997    2140.061204
998   -3297.934682
999   -2029.160693
Length: 1000, dtype: float64}
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9c534790&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0      -611.259513
1      2085.032085
2      -358.263795
3      -923.489532
4       303.066257
          ...
995     103.785324
996    -778.160424
997    2139.867530
998   -3296.607899
999   -2029.352445
Length: 1000, dtype: float64}
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9c534c40&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0      -613.293966
1      2083.015252
2      -357.727898
3      -923.619605
4       302.843817
          ...
995     102.892708
996    -778.536207
997    2137.846184
998   -3294.076819
999   -2026.775530
Length: 1000, dtype: float64}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
estimated effect [0.5, 0.5, 0.5, 0.5, 0.5]
new_effect [7.640367370180047, 3.077710331634722, -0.8174609187925054, 1.7877956045699919, -1.609700844459206]
p_value [0.0002383883555993276, 0.4358679687220849, 0.40167346997133335, 0.3593626265883955, 0.18778410128443734]
true value 1.0774793812218513


Running Experiment Number: 5


Current Sample Size: 1000


The current DGP:

        Linear Data Generating Process
        -------------------------------

        treatment:[&#39;t1&#39;]
        outcome:[&#39;y&#39;]
        confounder: [&#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;]
        effect_modifier: [&#39;x1&#39;, &#39;x2&#39;]
        weights: {&#39;confounder=&gt;treatment&#39;: array([[ 9.98161318e+01],
       [ 7.67455813e-01],
       [ 3.62915691e-01],
       [ 1.05586344e+00],
       [ 7.75895439e-03],
       [-1.09367047e+00]]), &#39;confounder=&gt;outcome&#39;: array([[ 9.99532559e+01],
       [-1.27434302e+00],
       [-1.80558175e+00],
       [-4.47829123e-02],
       [ 6.74768202e-01],
       [-6.50783073e-01]]), &#39;effect_modifier=&gt;outcome&#39;: array([[1.32321358],
       [0.22895323]]), &#39;treatment=&gt;outcome&#39;: array([[1.07747938]])}
        bias: {&#39;confounder=&gt;treatment&#39;: array([-1.21799807]), &#39;confounder=&gt;outcome&#39;: array([-0.59245996])}
        seed: None
        treatment_is_binary: True
        percentile: 0.9

printing data shape
(1000, 10)
[-1.15307991]
check
printing length of confounder list: 2
printing confounder list: [&#39;w2&#39;, &#39;w3&#39;]
data columns
data columns Index([&#39;x1&#39;, &#39;x2&#39;, &#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;, &#39;t1&#39;, &#39;y&#39;], dtype=&#39;object&#39;)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_dowhy_ranking_methods_24_94.png" src="../_images/example_notebooks_dowhy_ranking_methods_24_94.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
identified_estimand: Estimand type: nonparametric-ate

### Estimand : 1
Estimand name: backdoor
Estimand expression:
  d
─────(Expectation(y|w3,w2))
d[t₁]
Estimand assumption 1, Unconfoundedness: If U→{t1} and U→y then P(y|t1,w3,w2,U) = P(y|t1,w3,w2)

### Estimand : 2
Estimand name: iv
No such variable(s) found!

### Estimand : 3
Estimand name: frontdoor
No such variable(s) found!



Running the estimators:

The current estimator: Estimator(name=&#39;backdoor.linear_regression&#39;, params=None)
estimator.params None
linear_regression
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: None, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_matching&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_matching
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_weighting&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_weighting
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dml.DML&#39;, params={&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dr.LinearDRLearner&#39;, params={&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
estimate_values [60.90195149087615, 62.14326858425973, 60.78154476044857, 56.52686648126895, 60.99134237417991]


Running the refuters:

The current refuter: Refuter(name=&#39;dummy_outcome_refuter&#39;, params={&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0      -613.293966
1      2083.015252
2      -357.727898
3      -923.619605
4       302.843817
          ...
995     102.892708
996    -778.536207
997    2137.846184
998   -3294.076819
999   -2026.775530
Length: 1000, dtype: float64})
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9dd0b790&gt;
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0     -3940.006143
1        57.875134
2      -538.445820
3      2165.009963
4       884.111905
          ...
995   -1574.229519
996    1007.070162
997   -3138.699445
998    1731.831128
999   -2057.310511
Length: 1000, dtype: float64}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9c4d5490&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0     -3940.934745
1        59.032221
2      -537.947101
3      2168.746645
4       883.944058
          ...
995   -1576.597922
996    1007.114788
997   -3135.922153
998    1731.511928
999   -2055.909669
Length: 1000, dtype: float64}
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9c3efdc0&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0     -3940.015358
1        57.136932
2      -537.097275
3      2166.695690
4       884.343557
          ...
995   -1576.491235
996    1007.408465
997   -3138.089805
998    1731.398160
999   -2055.480534
Length: 1000, dtype: float64}
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9c850160&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0     -3939.466169
1        56.716418
2      -536.303930
3      2166.597613
4       883.777567
          ...
995   -1575.552812
996    1005.490149
997   -3136.488114
998    1731.955529
999   -2055.830075
Length: 1000, dtype: float64}
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9c4ebe20&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0     -3941.446499
1        56.028706
2      -538.269766
3      2166.394087
4       884.119455
          ...
995   -1575.765882
996    1007.516089
997   -3139.256146
998    1732.163642
999   -2056.692610
Length: 1000, dtype: float64}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
estimated effect [0.5, 0.5, 0.5, 0.5, 0.5]
new_effect [3.660603786059558, 9.502438736632557, 10.641296012021716, 0.8240471503601821, -1.306912551586894]
p_value [0.3623699585543172, 0.13533392433080038, 3.742748678297945e-08, 0.4920791292376824, 0.44480112296935204]
true value -1.1530799063330788


Running Experiment Number: 6


Current Sample Size: 1000


The current DGP:

        Linear Data Generating Process
        -------------------------------

        treatment:[&#39;t1&#39;]
        outcome:[&#39;y&#39;]
        confounder: [&#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;]
        effect_modifier: [&#39;x1&#39;, &#39;x2&#39;]
        weights: {&#39;confounder=&gt;treatment&#39;: array([[ 1.00440077e+02],
       [ 6.10206198e-02],
       [ 6.47894803e-01],
       [-1.08516042e+00],
       [ 9.13814565e-01],
       [ 6.49795595e-01]]), &#39;confounder=&gt;outcome&#39;: array([[ 9.97464988e+01],
       [ 9.55449622e-01],
       [-6.67849569e-02],
       [ 3.76789498e-01],
       [ 1.14456304e+00],
       [ 7.62076706e-01]]), &#39;effect_modifier=&gt;outcome&#39;: array([[ 0.19178167],
       [-0.36392913]]), &#39;treatment=&gt;outcome&#39;: array([[-1.15307991]])}
        bias: {&#39;confounder=&gt;treatment&#39;: array([0.66991406]), &#39;confounder=&gt;outcome&#39;: array([0.15729921])}
        seed: None
        treatment_is_binary: True
        percentile: 0.9

printing data shape
(1000, 10)
[1.70756199]
check
printing length of confounder list: 2
printing confounder list: [&#39;w2&#39;, &#39;w3&#39;]
data columns
data columns Index([&#39;x1&#39;, &#39;x2&#39;, &#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;, &#39;t1&#39;, &#39;y&#39;], dtype=&#39;object&#39;)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_dowhy_ranking_methods_24_112.png" src="../_images/example_notebooks_dowhy_ranking_methods_24_112.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
identified_estimand: Estimand type: nonparametric-ate

### Estimand : 1
Estimand name: backdoor
Estimand expression:
  d
─────(Expectation(y|w3,w2))
d[t₁]
Estimand assumption 1, Unconfoundedness: If U→{t1} and U→y then P(y|t1,w3,w2,U) = P(y|t1,w3,w2)

### Estimand : 2
Estimand name: iv
No such variable(s) found!

### Estimand : 3
Estimand name: frontdoor
No such variable(s) found!



Running the estimators:

The current estimator: Estimator(name=&#39;backdoor.linear_regression&#39;, params=None)
estimator.params None
linear_regression
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: None, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_matching&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_matching
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_weighting&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_weighting
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dml.DML&#39;, params={&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dr.LinearDRLearner&#39;, params={&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
estimate_values [65.04316243835534, 68.45048086874402, 64.49918743705354, 57.73476569915405, 64.9157693535279]


Running the refuters:

The current refuter: Refuter(name=&#39;dummy_outcome_refuter&#39;, params={&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0     -3941.446499
1        56.028706
2      -538.269766
3      2166.394087
4       884.119455
          ...
995   -1575.765882
996    1007.516089
997   -3139.256146
998    1732.163642
999   -2056.692610
Length: 1000, dtype: float64})
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9df56f40&gt;
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0      2107.816985
1     -2426.898726
2      1542.586302
3      -129.918479
4     -4101.928275
          ...
995    1150.392402
996    1617.615259
997    -479.641578
998    2581.244987
999    -364.084694
Length: 1000, dtype: float64}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9c850520&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0      2107.056942
1     -2426.313322
2      1541.542649
3      -131.607063
4     -4100.820905
          ...
995    1149.473059
996    1615.804367
997    -478.657442
998    2579.157048
999    -364.131825
Length: 1000, dtype: float64}
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9dd45490&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0      2105.252068
1     -2426.820050
2      1541.577361
3      -129.529517
4     -4101.243332
          ...
995    1150.321510
996    1618.956077
997    -479.136696
998    2579.593041
999    -365.491090
Length: 1000, dtype: float64}
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9dd0bfa0&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0      2108.037327
1     -2426.114242
2      1541.415935
3      -130.307257
4     -4101.434762
          ...
995    1149.459010
996    1618.285439
997    -479.590240
998    2579.783742
999    -366.096546
Length: 1000, dtype: float64}
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7fb046539880&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0      2106.902487
1     -2426.664068
2      1542.390334
3      -131.460297
4     -4099.631394
          ...
995    1148.775860
996    1616.640938
997    -478.259320
998    2579.284686
999    -366.936090
Length: 1000, dtype: float64}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
estimated effect [0.5, 0.5, 0.5, 0.5, 0.5]
new_effect [10.309063810505052, 15.423054550472674, 14.657223090623756, 12.764931213675306, 20.648387470879335]
p_value [0.09464160824074319, 0.24695774680744548, 0.07235351328516877, 0.1347308889832105, 0.029623453780040457]
true value 1.7075619894796057


Running Experiment Number: 7


Current Sample Size: 1000


The current DGP:

        Linear Data Generating Process
        -------------------------------

        treatment:[&#39;t1&#39;]
        outcome:[&#39;y&#39;]
        confounder: [&#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;]
        effect_modifier: [&#39;x1&#39;, &#39;x2&#39;]
        weights: {&#39;confounder=&gt;treatment&#39;: array([[ 9.91681818e+01],
       [-5.85033940e-02],
       [ 5.40793055e-01],
       [-6.63317348e-01],
       [ 1.16809183e+00],
       [ 2.71740312e-01]]), &#39;confounder=&gt;outcome&#39;: array([[99.45939974],
       [-0.49296959],
       [-0.32927634],
       [ 0.4369036 ],
       [-0.26957969],
       [-0.87605353]]), &#39;effect_modifier=&gt;outcome&#39;: array([[-1.03388727],
       [-0.91278597]]), &#39;treatment=&gt;outcome&#39;: array([[1.70756199]])}
        bias: {&#39;confounder=&gt;treatment&#39;: array([-0.83758994]), &#39;confounder=&gt;outcome&#39;: array([1.36687893])}
        seed: None
        treatment_is_binary: True
        percentile: 0.9

printing data shape
(1000, 10)
[0.40729453]
check
printing length of confounder list: 2
printing confounder list: [&#39;w2&#39;, &#39;w3&#39;]
data columns
data columns Index([&#39;x1&#39;, &#39;x2&#39;, &#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;, &#39;t1&#39;, &#39;y&#39;], dtype=&#39;object&#39;)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_dowhy_ranking_methods_24_132.png" src="../_images/example_notebooks_dowhy_ranking_methods_24_132.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
identified_estimand: Estimand type: nonparametric-ate

### Estimand : 1
Estimand name: backdoor
Estimand expression:
  d
─────(Expectation(y|w3,w2))
d[t₁]
Estimand assumption 1, Unconfoundedness: If U→{t1} and U→y then P(y|t1,w3,w2,U) = P(y|t1,w3,w2)

### Estimand : 2
Estimand name: iv
No such variable(s) found!

### Estimand : 3
Estimand name: frontdoor
No such variable(s) found!



Running the estimators:

The current estimator: Estimator(name=&#39;backdoor.linear_regression&#39;, params=None)
estimator.params None
linear_regression
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: None, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_matching&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_matching
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_weighting&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_weighting
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dml.DML&#39;, params={&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dr.LinearDRLearner&#39;, params={&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
estimate_values [63.37229404077416, 58.9770434400301, 64.14621436022367, 58.54347891723342, 63.448287471542045]


Running the refuters:

The current refuter: Refuter(name=&#39;dummy_outcome_refuter&#39;, params={&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0      2106.902487
1     -2426.664068
2      1542.390334
3      -131.460297
4     -4099.631394
          ...
995    1148.775860
996    1616.640938
997    -478.259320
998    2579.284686
999    -366.936090
Length: 1000, dtype: float64})
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9cbf23a0&gt;
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0     -1951.400102
1      -430.581020
2      -232.015938
3     -2087.157714
4        66.191357
          ...
995    2237.671248
996     667.310916
997   -3565.628209
998    -269.807913
999    1232.508037
Length: 1000, dtype: float64}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7fb04aec0af0&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0     -1952.577102
1      -426.524766
2      -234.026830
3     -2085.222343
4        66.177115
          ...
995    2236.274092
996     667.715330
997   -3564.500007
998    -269.398198
999    1231.757277
Length: 1000, dtype: float64}
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9c767b80&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0     -1953.244343
1      -428.713277
2      -231.456178
3     -2087.536895
4        66.916537
          ...
995    2237.682351
996     668.525614
997   -3564.042359
998    -271.068384
999    1230.880716
Length: 1000, dtype: float64}
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9de41d60&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0     -1951.611638
1      -426.637854
2      -236.134710
3     -2086.709449
4        64.143112
          ...
995    2238.378840
996     666.808738
997   -3562.871208
998    -270.491833
999    1231.238947
Length: 1000, dtype: float64}
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9c8f1670&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0     -1951.761944
1      -427.268123
2      -232.476258
3     -2087.221775
4        65.784166
          ...
995    2238.370380
996     665.829014
997   -3563.524784
998    -271.895238
999    1228.772586
Length: 1000, dtype: float64}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
estimated effect [0.5, 0.5, 0.5, 0.5, 0.5]
new_effect [-2.4961042747015236, 9.845226335401339, 7.846505244911273, 2.447142034250111, 3.3551810523535934]
p_value [0.3682185016906667, 0.2649484101592997, 0.20482027533564706, 0.34537406046142805, 0.3436112742267261]
true value 0.40729453036142144


Running Experiment Number: 8


Current Sample Size: 1000


The current DGP:

        Linear Data Generating Process
        -------------------------------

        treatment:[&#39;t1&#39;]
        outcome:[&#39;y&#39;]
        confounder: [&#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;]
        effect_modifier: [&#39;x1&#39;, &#39;x2&#39;]
        weights: {&#39;confounder=&gt;treatment&#39;: array([[9.83595442e+01],
       [1.32841310e+00],
       [4.73810127e-01],
       [8.91797943e-02],
       [6.25792837e-01],
       [1.53375622e+00]]), &#39;confounder=&gt;outcome&#39;: array([[ 9.84483212e+01],
       [ 6.09160632e-01],
       [-4.88511208e-02],
       [ 4.16060410e-01],
       [-9.44327068e-02],
       [ 2.26200717e-01]]), &#39;effect_modifier=&gt;outcome&#39;: array([[ 0.70735471],
       [-2.45276947]]), &#39;treatment=&gt;outcome&#39;: array([[0.40729453]])}
        bias: {&#39;confounder=&gt;treatment&#39;: array([-0.77428387]), &#39;confounder=&gt;outcome&#39;: array([0.54009229])}
        seed: None
        treatment_is_binary: True
        percentile: 0.9

printing data shape
(1000, 10)
[-2.34721906]
check
printing length of confounder list: 2
printing confounder list: [&#39;w2&#39;, &#39;w3&#39;]
data columns
data columns Index([&#39;x1&#39;, &#39;x2&#39;, &#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;, &#39;t1&#39;, &#39;y&#39;], dtype=&#39;object&#39;)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_dowhy_ranking_methods_24_150.png" src="../_images/example_notebooks_dowhy_ranking_methods_24_150.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
identified_estimand: Estimand type: nonparametric-ate

### Estimand : 1
Estimand name: backdoor
Estimand expression:
  d
─────(Expectation(y|w3,w2))
d[t₁]
Estimand assumption 1, Unconfoundedness: If U→{t1} and U→y then P(y|t1,w3,w2,U) = P(y|t1,w3,w2)

### Estimand : 2
Estimand name: iv
No such variable(s) found!

### Estimand : 3
Estimand name: frontdoor
No such variable(s) found!



Running the estimators:

The current estimator: Estimator(name=&#39;backdoor.linear_regression&#39;, params=None)
estimator.params None
linear_regression
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: None, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_matching&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_matching
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_weighting&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_weighting
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dml.DML&#39;, params={&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dr.LinearDRLearner&#39;, params={&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
estimate_values [66.00713410099637, 56.333282345047934, 66.40753990199842, 71.85247533841225, 65.90033605418922]


Running the refuters:

The current refuter: Refuter(name=&#39;dummy_outcome_refuter&#39;, params={&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0     -1951.761944
1      -427.268123
2      -232.476258
3     -2087.221775
4        65.784166
          ...
995    2238.370380
996     665.829014
997   -3563.524784
998    -271.895238
999    1228.772586
Length: 1000, dtype: float64})
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9de4d1c0&gt;
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0       -15.196140
1      -279.573157
2       780.549610
3      1172.971374
4       765.662503
          ...
995   -2076.934104
996     131.930140
997    1111.802991
998    1092.987857
999   -2325.761159
Length: 1000, dtype: float64}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9dd0ac40&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0       -13.127734
1      -280.773051
2       779.712511
3      1169.006962
4       767.928622
          ...
995   -2075.169433
996     130.912345
997    1113.427780
998    1094.925611
999   -2324.386684
Length: 1000, dtype: float64}
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9cc9b5b0&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0       -14.064421
1      -279.653484
2       781.668954
3      1169.923442
4       765.448493
          ...
995   -2075.583794
996     131.511478
997    1111.078520
998    1094.565099
999   -2326.350142
Length: 1000, dtype: float64}
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9c50eaf0&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0       -14.870922
1      -281.585064
2       780.581521
3      1169.210106
4       766.186631
          ...
995   -2073.476784
996     131.482516
997    1112.624108
998    1093.018824
999   -2325.871663
Length: 1000, dtype: float64}
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9cbe5d60&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0       -13.973706
1      -282.227817
2       780.927343
3      1170.358899
4       766.742834
          ...
995   -2074.514779
996     131.634136
997    1113.488895
998    1093.011181
999   -2324.553145
Length: 1000, dtype: float64}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
estimated effect [0.5, 0.5, 0.5, 0.5, 0.5]
new_effect [9.641824786384424, -0.008955685695380033, 0.841501281715567, 1.8786241492870768, -0.22377242475281314]
p_value [0.1380822161719502, 0.485086124452766, 0.48682337795745717, 0.3568378966178454, 0.45107395669526995]
true value -2.3472190598405294


Running Experiment Number: 9


Current Sample Size: 1000


The current DGP:

        Linear Data Generating Process
        -------------------------------

        treatment:[&#39;t1&#39;]
        outcome:[&#39;y&#39;]
        confounder: [&#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;]
        effect_modifier: [&#39;x1&#39;, &#39;x2&#39;]
        weights: {&#39;confounder=&gt;treatment&#39;: array([[100.19789996],
       [  1.28639011],
       [ -1.47857583],
       [  0.22886352],
       [  0.5130441 ],
       [  1.02902275]]), &#39;confounder=&gt;outcome&#39;: array([[101.06032215],
       [ -0.88876898],
       [ -0.30344102],
       [ -0.9875432 ],
       [ -1.71490036],
       [ -0.1811362 ]]), &#39;effect_modifier=&gt;outcome&#39;: array([[ 0.60975528],
       [-0.67742592]]), &#39;treatment=&gt;outcome&#39;: array([[-2.34721906]])}
        bias: {&#39;confounder=&gt;treatment&#39;: array([0.57691176]), &#39;confounder=&gt;outcome&#39;: array([-0.06576457])}
        seed: None
        treatment_is_binary: True
        percentile: 0.9

printing data shape
(1000, 10)
[-1.58077797]
check
printing length of confounder list: 2
printing confounder list: [&#39;w2&#39;, &#39;w3&#39;]
data columns
data columns Index([&#39;x1&#39;, &#39;x2&#39;, &#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;, &#39;w4&#39;, &#39;w5&#39;, &#39;w6&#39;, &#39;t1&#39;, &#39;y&#39;], dtype=&#39;object&#39;)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_dowhy_ranking_methods_24_168.png" src="../_images/example_notebooks_dowhy_ranking_methods_24_168.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
identified_estimand: Estimand type: nonparametric-ate

### Estimand : 1
Estimand name: backdoor
Estimand expression:
  d
─────(Expectation(y|w3,w2))
d[t₁]
Estimand assumption 1, Unconfoundedness: If U→{t1} and U→y then P(y|t1,w3,w2,U) = P(y|t1,w3,w2)

### Estimand : 2
Estimand name: iv
No such variable(s) found!

### Estimand : 3
Estimand name: frontdoor
No such variable(s) found!



Running the estimators:

The current estimator: Estimator(name=&#39;backdoor.linear_regression&#39;, params=None)
estimator.params None
linear_regression
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: None, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_matching&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_matching
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.propensity_score_weighting&#39;, params={&#39;init_params&#39;: {}})
estimator.params {&#39;init_params&#39;: {}}
propensity_score_weighting
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dml.DML&#39;, params={&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_y&#39;: GradientBoostingRegressor(), &#39;model_t&#39;: GradientBoostingRegressor(), &#39;model_final&#39;: LassoCV(fit_intercept=False), &#39;featurizer&#39;: PolynomialFeatures(degree=1)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dml.DML&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
The current estimator: Estimator(name=&#39;backdoor.econml.dr.LinearDRLearner&#39;, params={&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;})
estimator.params {&#39;init_params&#39;: {&#39;model_propensity&#39;: LogisticRegressionCV(cv=3)}, &#39;fit_params&#39;: {}, &#39;econml_methodname&#39;: &#39;econml.dr.LinearDRLearner&#39;}
printing estimate&#39;s type
&lt;class &#39;dowhy.causal_estimator.CausalEstimate&#39;&gt;
estimate_values [46.77177553626156, 52.2041236496697, 47.25887731206704, 27.715622055055274, 47.46288348393391]


Running the refuters:

The current refuter: Refuter(name=&#39;dummy_outcome_refuter&#39;, params={&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0       -13.973706
1      -282.227817
2       780.927343
3      1170.358899
4       766.742834
          ...
995   -2074.514779
996     131.634136
997    1113.488895
998    1093.011181
999   -2324.553145
Length: 1000, dtype: float64})
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9c608a60&gt;
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0       903.312521
1      1374.710658
2      -928.743749
3     -1010.232128
4        41.016032
          ...
995    -806.820152
996    2445.177241
997    1161.375072
998     387.432267
999     997.818019
Length: 1000, dtype: float64}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
{&#39;control_value&#39;: 0, &#39;treatment_value&#39;: 1, &#39;test_significance&#39;: False, &#39;evaluate_effect_strength&#39;: False, &#39;confidence_intervals&#39;: False, &#39;target_units&#39;: &#39;ate&#39;, &#39;effect_modifiers&#39;: [&#39;x1&#39;, &#39;x2&#39;]}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
divide by zero encountered in double_scalars
divide by zero encountered in double_scalars
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9cacd0d0&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0       903.628532
1      1373.779170
2      -926.835565
3     -1009.887655
4        40.572287
          ...
995    -806.398003
996    2443.298073
997    1160.288260
998     387.683139
999     999.822091
Length: 1000, dtype: float64}
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9c8611c0&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0       902.223348
1      1373.433385
2      -924.481668
3     -1011.004643
4        38.741596
          ...
995    -804.520089
996    2444.155225
997    1162.623017
998     386.748922
999     996.020121
Length: 1000, dtype: float64}
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9dd45be0&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0       903.516138
1      1374.677365
2      -926.204367
3     -1009.776309
4        40.619860
          ...
995    -807.420520
996    2444.782773
997    1161.534650
998     388.226191
999     998.486042
Length: 1000, dtype: float64}
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
********%%%%%%%%%$$$$$&amp;&amp;^**^^^^*^*^*
add_unobserved_confounder &lt;dowhy.causal_refuters.add_unobserved_common_cause.AddUnobservedCommonCause object at 0x7faf9dd42f70&gt;
refuter.params {&#39;num_simulations&#39;: 5, &#39;transformation_list&#39;: [(&#39;random_forest&#39;, {&#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 6})], &#39;true_causal_effect&#39;: &lt;function &lt;lambda&gt; at 0x7fb04ac00160&gt;, &#39;unobserved_confounder_values&#39;: 0       901.687764
1      1372.355465
2      -924.904696
3     -1009.611363
4        41.314998
          ...
995    -805.361238
996    2444.371479
997    1162.215976
998     387.326429
999     999.969821
Length: 1000, dtype: float64}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
printing refute&#39;s type
&lt;class &#39;list&#39;&gt;
estimated effect [0.5, 0.5, 0.5, 0.5, 0.5]
new_effect [0.6841080872482875, 8.77515780542652, 6.445123397529999, 3.9695575210615104, 0.3134585090102121]
p_value [0.48602406699494244, 2.5268983369895157e-19, 0.19202164459637933, 0.3907423091845138, 0.4881057111162118]
true value -1.580777965955537


Completed all experiments. Saving the data...
Data has been saved in  results/Test_2_2022-03-20_data.csv
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Co-variance matrix is underdetermined. Inference will be invalid!
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">##This plot shows the Mean Absolute Error of the Orginal Estimate from the true value and of the New Effect from</span>
<span class="c1">#the expected value for each estimator.</span>
<span class="n">plot_MAEs</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_dowhy_ranking_methods_25_0.png" src="../_images/example_notebooks_dowhy_ranking_methods_25_0.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Printing MAE of various estimates:
ORIGINAL_ESTIMATE:backdoor.propensity_score_matching 63.12479489287623
ORIGINAL_ESTIMATE:backdoor.econml.dr.LinearDRLearner 62.15975668060298
ORIGINAL_ESTIMATE:backdoor.linear_regression 62.09580481708018
ORIGINAL_ESTIMATE:backdoor.econml.dml.DML 57.384336172932024
dummy_outcome_refuter:backdoor.propensity_score_weighting:NEW_EFFECT 7.347641977619976
dummy_outcome_refuter:backdoor.propensity_score_matching:NEW_EFFECT 7.0702575346901595
dummy_outcome_refuter:backdoor.linear_regression:NEW_EFFECT 6.174788195733241
dummy_outcome_refuter:backdoor.econml.dr.LinearDRLearner:NEW_EFFECT 5.640806894803817
dummy_outcome_refuter:backdoor.econml.dml.DML:NEW_EFFECT 4.506668497416721
dummy_outcome_refuter:backdoor.linear_regression:P_VALUE 1.330096404757747
dummy_outcome_refuter:backdoor.econml.dr.LinearDRLearner:P_VALUE 1.293166809125902
dummy_outcome_refuter:backdoor.linear_regression:ESTIMATED_EFFECT 1.2797882604285742
dummy_outcome_refuter:backdoor.propensity_score_matching:ESTIMATED_EFFECT 1.2797882604285742
dummy_outcome_refuter:backdoor.propensity_score_weighting:ESTIMATED_EFFECT 1.2797882604285742
dummy_outcome_refuter:backdoor.econml.dml.DML:ESTIMATED_EFFECT 1.2797882604285742
dummy_outcome_refuter:backdoor.econml.dr.LinearDRLearner:ESTIMATED_EFFECT 1.2797882604285742
dummy_outcome_refuter:backdoor.econml.dml.DML:P_VALUE 1.2540267882032945
dummy_outcome_refuter:backdoor.propensity_score_matching:P_VALUE 1.2112612057307284
dummy_outcome_refuter:backdoor.propensity_score_weighting:P_VALUE 1.2019770491571322
</pre></div></div>
</div>
<section id="id1">
<h2>Ranking based on Original Estimate<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h2>
<p>The Original Estimate is calculated in the presence of the True Value (that is, the ground truth). However in many real life datasets, the ground truth may not be known. Hence, we want the ranking produced by our refutation tests to be in coherence with that obtained from the Original Estimates. According to the Original Estimate values, the ranking of the estimators should be as follows (the method with the least MAE should get the best rank): 1. DMLCateEstimator 2. Propensity Score Matching 3.
LinearRegression 4. LinearDRLearner</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#This plot shows the deviation of the original estimate, the new effect and the estimated effect from the true value</span>
<span class="n">refuter</span> <span class="o">=</span> <span class="s1">&#39;dummy_outcome_refuter&#39;</span>
<span class="n">deviation_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">estimator</span> <span class="ow">in</span> <span class="n">estimator_list</span><span class="p">:</span>
    <span class="n">plot_estimators_and_refuters</span><span class="p">(</span><span class="n">refuter</span><span class="p">,</span> <span class="n">estimator</span><span class="p">)</span>
    <span class="n">avg_deviation</span> <span class="o">=</span> <span class="p">((</span><span class="n">res</span><span class="p">[</span><span class="n">refuter</span><span class="o">+</span><span class="s1">&#39;:&#39;</span><span class="o">+</span><span class="n">estimator</span><span class="o">+</span><span class="s1">&#39;:NEW_EFFECT&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">avg_deviation</span><span class="p">)</span>
    <span class="n">deviation_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">avg_deviation</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_dowhy_ranking_methods_28_0.png" src="../_images/example_notebooks_dowhy_ranking_methods_28_0.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
53.84062975938087
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_dowhy_ranking_methods_28_2.png" src="../_images/example_notebooks_dowhy_ranking_methods_28_2.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
68.45297729256416
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_dowhy_ranking_methods_28_4.png" src="../_images/example_notebooks_dowhy_ranking_methods_28_4.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
42.96623038634156
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_dowhy_ranking_methods_28_6.png" src="../_images/example_notebooks_dowhy_ranking_methods_28_6.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
48.625588618342775
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;Figure size 432x288 with 0 Axes&gt;
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_deviations</span><span class="p">(</span><span class="n">estimator_list</span><span class="p">,</span> <span class="n">deviation_list</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">estimator_list</span><span class="p">)):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">estimator_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span><span class="s2">&quot;: &quot;</span><span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">deviation_list</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_dowhy_ranking_methods_29_0.png" src="../_images/example_notebooks_dowhy_ranking_methods_29_0.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
backdoor.linear_regression: 53.84062975938087
backdoor.propensity_score_matching: 68.45297729256416
backdoor.econml.dml.DML: 42.96623038634156
backdoor.econml.dr.LinearDRLearner: 48.625588618342775
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">estimator_list</span><span class="p">,</span> <span class="n">deviation_list</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">item</span><span class="p">:</span> <span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)}</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;backdoor.propensity_score_matching&#39;: 68.45297729256416,
 &#39;backdoor.linear_regression&#39;: 53.84062975938087,
 &#39;backdoor.econml.dr.LinearDRLearner&#39;: 48.625588618342775,
 &#39;backdoor.econml.dml.DML&#39;: 42.96623038634156}
</pre></div></div>
</div>
</section>
<section id="id2">
<h2>Ranking based on New Effect (Refutatation results)<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h2>
<p>The ranking based on absolute value of deviations is : 1. DML 2. Linear DR Learner 3. Propensity Score Matching 4. Linear Regression</p>
<section id="We-can-see-that-this-ranking-produces-the-same-top-ranked-estimator-as-the-one-based-on-Original-Estimate.-Thus-ranking-based-on-the-unobserved-confounding-error-solves-the-problem-and-gives-us-a-close-to-correct-ranking-amongst-methods.">
<h3>We can see that this ranking produces the same top-ranked estimator as the one based on Original Estimate. Thus ranking based on the unobserved confounding error solves the problem and gives us a close-to-correct ranking amongst methods.<a class="headerlink" href="#We-can-see-that-this-ranking-produces-the-same-top-ranked-estimator-as-the-one-based-on-Original-Estimate.-Thus-ranking-based-on-the-unobserved-confounding-error-solves-the-problem-and-gives-us-a-close-to-correct-ranking-amongst-methods." title="Permalink to this headline"></a></h3>
</section>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, Microsoft.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>